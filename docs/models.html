---

title: Models


keywords: fastai
sidebar: home_sidebar

summary: "Pytorch segmentation models."
description: "Pytorch segmentation models."
nb_path: "nbs/01_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SegformerForSemanticSegmentation</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;nvidia/segformer-b0-finetuned-ade-512-512&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transformers/Huggingface-Integration">Transformers/Huggingface Integration<a class="anchor-link" href="#Transformers/Huggingface-Integration"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SegFormer" class="doc_header"><code>class</code> <code>SegFormer</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L25" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SegFormer</code>(<strong><code>classes</code></strong>=<em><code>2</code></em>, <strong><code>in_channels</code></strong>=<em><code>1</code></em>, <strong><code>encoder_weights</code></strong>=<em><code>'segformer-b0-finetuned-ade-512-512'</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SegFormer</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading weights: segformer-b0-finetuned-ade-512-512
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:
- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated
- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated
- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Segmenation-Models-Pytorch-Integration">Segmenation Models Pytorch Integration<a class="anchor-link" href="#Segmenation-Models-Pytorch-Integration"> </a></h2><p>From the website:</p>
<ul>
<li>High level API (just two lines to create a neural network)</li>
<li>9 models architectures for binary and multi class segmentation (including legendary Unet)</li>
<li>104 available encoders</li>
<li>All encoders have pre-trained weights for faster and better convergence</li>
</ul>
<p>See <a href="https://github.com/qubvel/segmentation_models.pytorch">https://github.com/qubvel/segmentation_models.pytorch</a> for API details.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_pretrained_options" class="doc_header"><code>get_pretrained_options</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L42" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_pretrained_options</code>(<strong><code>encoder_name</code></strong>)</p>
</blockquote>
<p>Return available options for pretrained weights for a given encoder</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_smp_model" class="doc_header"><code>create_smp_model</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L48" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_smp_model</code>(<strong><code>arch</code></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Create segmentation_models_pytorch model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">tile_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">512</span><span class="p">]</span> <span class="c1">#1024</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#1,3,4</span>
<span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># 2,5</span>
<span class="n">encoders</span> <span class="o">=</span> <span class="n">ENCODERS</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="c1">#+ENCODERS[-1:]</span>

<span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tile_shapes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">in_c</span> <span class="ow">in</span> <span class="n">in_channels</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">ts</span><span class="p">)</span>
            <span class="n">out_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">ts</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">ARCHITECTURES</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">encoder_name</span> <span class="ow">in</span> <span class="n">encoders</span><span class="p">:</span>
                    <span class="n">model</span> <span class="o">=</span> <span class="n">create_smp_model</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="n">arch</span><span class="p">,</span> 
                                             <span class="n">encoder_name</span><span class="o">=</span><span class="n">encoder_name</span><span class="p">,</span>
                                             <span class="c1">#encoder_weights=None,</span>
                                             <span class="n">in_channels</span><span class="o">=</span><span class="n">in_c</span><span class="p">,</span> 
                                             <span class="n">classes</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
                    <span class="n">test_eq</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">)</span>
<span class="k">del</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading weights: segformer-b0-finetuned-ade-512-512
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:
- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated
- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated
- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="save_smp_model" class="doc_header"><code>save_smp_model</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L69" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>save_smp_model</code>(<strong><code>model</code></strong>, <strong><code>arch</code></strong>, <strong><code>path</code></strong>, <strong><code>stats</code></strong>=<em><code>None</code></em>, <strong><code>pickle_protocol</code></strong>=<em><code>2</code></em>)</p>
</blockquote>
<p>Save smp model, optionally including  stats</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch</span> <span class="o">=</span> <span class="s1">&#39;Unet&#39;</span>
<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;tst.pth&#39;</span>
<span class="n">stats</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;encoder_name&#39;</span><span class="p">:</span> <span class="s1">&#39;resnet34&#39;</span><span class="p">}</span>
<span class="n">tst</span> <span class="o">=</span> <span class="n">create_smp_model</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">save_smp_model</span><span class="p">(</span><span class="n">tst</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">stats</span><span class="o">=</span><span class="n">stats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arch</span> <span class="o">=</span> <span class="s1">&#39;SegFormer&#39;</span>
<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;tst.pth&#39;</span>
<span class="n">stats</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;encoder_name&#39;</span><span class="p">:</span> <span class="s1">&#39;resnet34&#39;</span><span class="p">}</span>
<span class="n">tst</span> <span class="o">=</span> <span class="n">create_smp_model</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">save_smp_model</span><span class="p">(</span><span class="n">tst</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">stats</span><span class="o">=</span><span class="n">stats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading weights: segformer-b0-finetuned-ade-512-512
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:
- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated
- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated
- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_smp_model" class="doc_header"><code>load_smp_model</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L78" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_smp_model</code>(<strong><code>path</code></strong>, <strong><code>device</code></strong>=<em><code>None</code></em>, <strong><code>strict</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Loads smp model from file</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tst2</span><span class="p">,</span> <span class="n">stats2</span> <span class="o">=</span> <span class="n">load_smp_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tst</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">tst2</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
    <span class="n">test_eq</span><span class="p">(</span><span class="n">p1</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">p2</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="n">stats2</span><span class="p">)</span>
<span class="n">path</span><span class="o">.</span><span class="n">unlink</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading weights: segformer-b0-finetuned-ade-512-512
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:
- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated
- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated
- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cellpose-integration">Cellpose integration<a class="anchor-link" href="#Cellpose-integration"> </a></h2><p>for reliable cell and nucleus segmentation. Visit <a href="https://github.com/MouseLand/cellpose">cellpose</a> for more information.</p>
<p>Cellpose integration for deepflash2 is tested on version 0.6.6.dev13+g316927e</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="check_cellpose_installation" class="doc_header"><code>check_cellpose_installation</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L91" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>check_cellpose_installation</code>(<strong><code>show_progress</code></strong>=<em><code>True</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_diameters" class="doc_header"><code>get_diameters</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L105" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_diameters</code>(<strong><code>masks</code></strong>)</p>
</blockquote>
<p>Get diameters from deepflash2 prediction</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="run_cellpose" class="doc_header"><code>run_cellpose</code><a href="https://github.com/matjesg/deepflash2/tree/master/deepflash2/models.py#L115" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>run_cellpose</code>(<strong><code>probs</code></strong>, <strong><code>masks</code></strong>, <strong><code>model_type</code></strong>=<em><code>'nuclei'</code></em>, <strong><code>diameter</code></strong>=<em><code>0</code></em>, <strong><code>min_size</code></strong>=<em><code>-1</code></em>, <strong><code>gpu</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>Run cellpose on deepflash2 predictions</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span><span class="mi">512</span><span class="p">)]</span>
<span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">&gt;</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">probs</span><span class="p">]</span>
<span class="n">cp_preds</span> <span class="o">=</span> <span class="n">run_cellpose</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">diameter</span><span class="o">=</span><span class="mf">17.</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cp_preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Using diameter of 17.0
2021-12-08 18:18:19,522 [INFO] WRITING LOG OUTPUT TO /media/data/home/mag01ud/.cellpose/run.log
2021-12-08 18:18:20,717 [INFO] ** TORCH CUDA version installed and working. **
2021-12-08 18:18:20,718 [INFO] &gt;&gt;&gt;&gt; using GPU
2021-12-08 18:18:20,761 [INFO] ~~~ FINDING MASKS ~~~
2021-12-08 18:18:22,600 [INFO] &gt;&gt;&gt;&gt; TOTAL TIME 1.84 sec
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

