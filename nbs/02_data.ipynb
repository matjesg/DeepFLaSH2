{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "import matplotlib.patches as patches\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, zarr, cv2, imageio, shutil, random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as AF\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> This module defines tools for image data preprocessing and real-time data augmentation that is used to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show(*obj, file_name=None, overlay=False, pred=False,\n",
    "         show_bbox=True, figsize=(10,10), cmap='binary_r', **kwargs):\n",
    "    \"Show image, mask, and weight (optional)\"\n",
    "    if len(obj)==3:\n",
    "        img,msk,weight = obj\n",
    "    elif len(obj)==2:\n",
    "        img,msk = obj\n",
    "        weight = None\n",
    "    elif len(obj)==1:\n",
    "        img = obj[0]\n",
    "        msk, weight = None, None\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f'Function not defined for {len(obj)} arguments.')\n",
    "    \n",
    "    # Image preprocessing\n",
    "    img = np.array(img)\n",
    "    # Swap axis to channels last\n",
    "    if img.shape[0]<20: img=np.moveaxis(img,0,-1)\n",
    "    # One channel images\n",
    "    if img.ndim == 3 and img.shape[-1] == 1: \n",
    "        img=img[...,0]\n",
    "\n",
    "    # Mask preprocessing\n",
    "    if msk is not None:\n",
    "        msk = np.array(msk)\n",
    "        # Remove background class from masks\n",
    "        if msk.shape[0]==2: msk=msk[1,...]\n",
    "        # Create bbox\n",
    "\n",
    "        pad = (np.array(img.shape[:2])-np.array(msk.shape))//2\n",
    "        bbox = Rectangle((pad[0]-1,pad[1]-1),img.shape[0]-2*pad[0]+1,img.shape[0]-2*pad[0]+1,\n",
    "                 edgecolor='r',linewidth=1,facecolor='none')\n",
    "\n",
    "        # Padding mask and weights\n",
    "        msk = np.pad(msk, pad, 'constant', constant_values=(0))\n",
    "\n",
    "        if cmap is None:\n",
    "            cmap = 'binary_r' if msk.max()==1 else cmap\n",
    "    \n",
    "    # Weights preprocessing\n",
    "    if weight is not None:\n",
    "        weight = np.array(weight)\n",
    "        weight = np.pad(weight, pad, 'constant', constant_values=(0))\n",
    "\n",
    "    ncol=1 if msk is None else 2\n",
    "    ncol=ncol if weight is None else ncol+1\n",
    "    fig, ax = plt.subplots(1,ncol,figsize=figsize)\n",
    "    img_ax = ax[0] if ncol>1 else ax\n",
    "    \n",
    "    # Plot img\n",
    "    img_ax.imshow(img, cmap=cmap)\n",
    "    if file_name is not None:\n",
    "        img_ax.set_title('Image {}'.format(file_name))\n",
    "    else:\n",
    "        img_ax.set_title('Image')\n",
    "    img_ax.set_axis_off()\n",
    "\n",
    "    # Plot img and mask\n",
    "    if msk is not None:\n",
    "        if overlay:\n",
    "            label_image = label(msk)\n",
    "            img_l2o = label2rgb(label_image, image=img, bg_label=0, alpha=.8, image_alpha=1)\n",
    "            ax[1].set_title('Image + Mask (#ROIs: {})'.format(label_image.max()))\n",
    "            ax[1].imshow(img_l2o)\n",
    "        else:\n",
    "            ax[1].imshow(msk, cmap=cmap)\n",
    "            ax[1].set_title('Mask')\n",
    "        if show_bbox: ax[1].add_patch(copy(bbox))\n",
    "\n",
    "        ax[1].set_axis_off()\n",
    "\n",
    "    # Plot weights\n",
    "    if weight is not None:\n",
    "        max_w = weight.max()\n",
    "        vmax_w = max(1, max_w)\n",
    "        ax[2].imshow(weight, vmax=vmax_w, cmap=cmap)\n",
    "        if pred:\n",
    "            ax[2].set_title('Prediction')\n",
    "        else:\n",
    "            ax[2].set_title('Weights (max value: {:.{p}f})'.format(max_w, p=1))\n",
    "        if show_bbox: ax[2].add_patch(copy(bbox))\n",
    "        ax[2].set_axis_off()\n",
    "\n",
    "    #ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show methods in fastai all rely on some types being able to show themselves. We create a new type with a show method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typedispatch\n",
    "\n",
    "Custom `show_batch` and `show_results` for  `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x:TensorImage, y:tuple, samples, max_n=6, figsize=None, **kwargs):\n",
    "    \"Show one batch (image, mask, and weights) from a `DataLoader`\"\n",
    "    max_n = np.min((max_n, len(x)))\n",
    "    if figsize is None: figsize = (12, max_n * 5)\n",
    "    for i in range(max_n): show(x[i], y[0][i], y[1][i], figsize=figsize, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:TensorImage, y:tuple, samples, outs, max_n=4, figsize=None, **kwargs):\n",
    "    \"Show image, mask, and weights from `max_n` items\"\n",
    "    max_n = np.min((max_n, len(x)))\n",
    "    if figsize is None: figsize = (12, max_n * 5)\n",
    "    for i in range(max_n): show(x[i], y[0][i], outs[i][0], pred=True, figsize=figsize, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example image and mask__\n",
    "\n",
    "We will use an example image and mask to guide through the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Generate an initial random image and mask with two circles\n",
    "x, y = np.indices((540, 540))\n",
    "x1, y1, x2, y2 = 180, 180, 41*7, 52*7\n",
    "r1, r2 = 10*7.20, 20*7\n",
    "mask_circle1 = (x - x1) ** 2 + (y - y1) ** 2 < r1 ** 2\n",
    "mask_circle2 = (x - x2) ** 2 + (y - y2) ** 2 < r2 ** 2\n",
    "mask = np.logical_or(mask_circle1, mask_circle2).astype(int)\n",
    "mask[:10,:] = 1\n",
    "mask[-10:,:] = 1\n",
    "mask[:,:10] = 1\n",
    "mask[:,-10:] = 1\n",
    "inst_labels, _ = ndimage.measurements.label(mask)\n",
    "image = np.random.rand(*mask.shape)+mask*2.\n",
    "path=Path('sample_data')\n",
    "(path/'images').mkdir(parents=True, exist_ok=True)\n",
    "imageio.imsave(path/'images'/'01.png', image)\n",
    "(path/'labels').mkdir(parents=True, exist_ok=True)\n",
    "imageio.imsave(path/'labels'/'01_mask.png', (mask*255).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def _show(*args, cmap = 'binary_r'):\n",
    "    figsize=(3*len(args),6)\n",
    "    fig, ax = plt.subplots(1, ncols=len(args),figsize=figsize, squeeze=False)\n",
    "    for i,x in enumerate(args):\n",
    "        ax[0,i].imshow(x, cmap=cmap)\n",
    "        ax[0,i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot example image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(path/'images'/'01.png')\n",
    "mask = imageio.imread(path/'labels'/'01_mask.png')\n",
    "show(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported segmentation mask types:\n",
    "\n",
    "**Class labels**: pixel annotations of classes (e.g., 0 for background and 1...n for positive classes) <br>\n",
    "**Instance labels**: pixel annotation of belonggig to different instance (e.g., 0 for background, 1 for first ROI, 2 for second ROI, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_show(mask, inst_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided segmentation masks are preprocessed to \n",
    "- convert instance labels to class labels\n",
    "- draw small ridges between touching instances (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# adapted from Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70.\n",
    "def preprocess_mask(clabels=None, instlabels=None, ignore=None, remove_overlap=True, n_dims = 2):\n",
    "    \"Calculates the weights from the given mask (classlabels `clabels` or `instlabels`).\"\n",
    "\n",
    "    assert not (clabels is None and instlabels is None), \"Provide either clabels or instlabels\"\n",
    "\n",
    "    # If no classlabels are given treat the problem as binary segmentation\n",
    "    # ==> Create a new array assigning class 1 (foreground) to each instance\n",
    "    if clabels is None:\n",
    "        clabels = (instlabels[:] > 0).astype(int)\n",
    "    else: clabels = np.array(clabels[:])\n",
    "\n",
    "    if remove_overlap:\n",
    "        # Initialize label and weights arrays with background\n",
    "        labels = np.zeros_like(clabels)\n",
    "        classes = np.unique(clabels)[1:]\n",
    "        # If no instance labels are given, generate them now\n",
    "        if instlabels is None:\n",
    "            # Creating instance labels from mask\n",
    "            instlabels = np.zeros_like(clabels)\n",
    "            nextInstance = 1\n",
    "            for c in classes:\n",
    "                #comps2, nInstances2 = ndimage.measurements.label(clabels == c)\n",
    "                nInstances, comps = cv2.connectedComponents((clabels[:] == c).astype('uint8'), connectivity=4)\n",
    "                nInstances -=1\n",
    "                instlabels[comps > 0] = comps[comps > 0] + nextInstance\n",
    "                nextInstance += nInstances\n",
    "\n",
    "        for c in classes:\n",
    "            # Extract all instance labels of class c\n",
    "            il = (instlabels * (clabels[:] == c)).astype(np.int16)\n",
    "            instances = np.unique(il)[1:]\n",
    "\n",
    "            # Generate background ridges between touching instances\n",
    "            # of that class, avoid overlapping instances\n",
    "            dil = cv2.morphologyEx(il, cv2.MORPH_CLOSE, kernel=np.ones((3,) * n_dims))\n",
    "            overlap_cand = np.unique(np.where(dil!=il, dil, 0))        \n",
    "            labels[np.isin(il, overlap_cand, invert=True)] = c\n",
    "\n",
    "            for instance in overlap_cand[1:]:\n",
    "                objectMaskDil = cv2.dilate((labels == c).astype('uint8'), kernel=np.ones((3,) * n_dims),iterations = 1)\n",
    "                labels[(instlabels == instance) & (objectMaskDil == 0)] = c\n",
    "    else:\n",
    "        labels = clabels        \n",
    "\n",
    "    return labels#.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments in `preprocess_masks`:\n",
    "- `clabels`: class labels (segmentation mask), \n",
    "- `instlabels`: instance labels (segmentation mask), \n",
    "- `n_dims` (int) = number of classes for `clabels` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst1 = preprocess_mask(mask, remove_overlap=False)\n",
    "tst2 = preprocess_mask(mask, remove_overlap=True)\n",
    "_show(tst1,tst2)\n",
    "ind = (slice(200,230), slice(230,260))\n",
    "print('Zoom in on borders:')\n",
    "_show(tst1[ind], tst2[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deformation field class to ensure that all augmentations are performed equally on images, masks, and weights. Implemented augmentations are\n",
    "- rotation\n",
    "- mirroring\n",
    "- random deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# adapted from Falk, Thorsten, et al. \"U-Net: deep learning for cell counting, detection, and morphometry.\" Nature methods 16.1 (2019): 67-70.\n",
    "class DeformationField:\n",
    "    \"Creates a deformation field for data augmentation\"\n",
    "    def __init__(self, shape=(540, 540), scale=1, scale_range=(0,0), p_scale=1.):\n",
    "        self.shape = shape\n",
    "        self.default_scale = self.scale = scale\n",
    "        \n",
    "        if random.random()<p_scale and sum(scale_range)!=0: \n",
    "            self.scale = random.uniform(*np.array(scale_range)*scale)\n",
    "        \n",
    "        grid_range = [np.linspace(-(d*self.scale)/2, ((d*self.scale)/2)-1, d) for d in shape] \n",
    "        self.deformationField = np.meshgrid(*grid_range)[::-1]\n",
    "\n",
    "    def rotate(self, theta=0):\n",
    "        \"Rotate deformation field\"\n",
    "        self.deformationField = [\n",
    "                self.deformationField[0] * np.cos(theta)\n",
    "                + self.deformationField[1] * np.sin(theta),\n",
    "                -self.deformationField[0] * np.sin(theta)\n",
    "                + self.deformationField[1] * np.cos(theta),\n",
    "            ]\n",
    "\n",
    "    def add_random_rotation(self, rotation_range_deg, p=0.5):\n",
    "        'Add random rotation'\n",
    "        if (random.random() < p):\n",
    "            self.rotate(\n",
    "                    theta=np.pi * (random.random()\n",
    "                                * (rotation_range_deg[1] - rotation_range_deg[0])\n",
    "                                +  rotation_range_deg[0])\n",
    "                                / 180.0)\n",
    "        \n",
    "    def mirror(self, dims):\n",
    "        \"Mirror deformation fild at dims\"\n",
    "        for d in range(len(self.shape)):\n",
    "            if dims[d]:\n",
    "                self.deformationField[d] = -self.deformationField[d]\n",
    "\n",
    "    def add_random_flip(self, p=0.5):\n",
    "        \"Add random flip\"\n",
    "        if (random.random() < p):\n",
    "            self.mirror(np.random.choice((True,False),2))    \n",
    "    \n",
    "    def get(self, offset=(0, 0), pad=(0, 0)):\n",
    "        \"Get relevant slice from deformation field\"\n",
    "        sliceDef = tuple(slice(int(p / 2), int(-p / 2)) if p > 0 else None for p in pad)\n",
    "        deform = [d[sliceDef] for d in self.deformationField]\n",
    "        return [d + offs for (d, offs) in zip(deform, offset)]\n",
    "\n",
    "    \n",
    "    def apply(self, data, offset=(0, 0), pad=(0, 0), order=1):\n",
    "        \"Apply deformation field to image using interpolation\"\n",
    "              \n",
    "        outshape = tuple(int(s - p) for (s, p) in zip(self.shape, pad))\n",
    "        coords = [np.squeeze(d).astype('float32').reshape(*outshape) for d in self.get(offset, pad)]\n",
    "        \n",
    "        # Get slices to avoid loading all data (.zarr files)\n",
    "        sl = []\n",
    "        for i in range(len(coords)):\n",
    "            cmin, cmax = int(coords[i].min()), int(coords[i].max())\n",
    "            dmax = data.shape[i]\n",
    "            if cmin<0: \n",
    "                cmax = max(-cmin, cmax)\n",
    "                cmin = 0 \n",
    "            elif cmax>dmax:\n",
    "                cmin = min(cmin, 2*dmax-cmax)\n",
    "                cmax = dmax\n",
    "                coords[i] -= cmin\n",
    "            else: coords[i] -= cmin\n",
    "            sl.append(slice(cmin, cmax))  \n",
    "            \n",
    "            \n",
    "        remap_fn = A.augmentations.functional._maybe_process_in_chunks(\n",
    "            cv2.remap, map1=coords[1],map2=coords[0], interpolation=order, borderMode=cv2.BORDER_REFLECT\n",
    "        )\n",
    "        return remap_fn(data[tuple(sl)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = DeformationField(shape=(260, 260), scale=1, scale_range=(0.7, 1.4))\n",
    "show(tst.apply(image, offset=(270,270)), \n",
    "     tst.apply(mask, offset=(270,270)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add mirroring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = DeformationField()\n",
    "tst.mirror((1,1))\n",
    "show(tst.apply(image, offset=(270,270)), \n",
    "     tst.apply(mask, offset=(270,270)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.rotate(1)\n",
    "show(tst.apply(image, offset=(270,270)), \n",
    "     tst.apply(mask, offset=(270,270)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Pytorch map-style [datasets](https://pytorch.org/docs/stable/data.html) for training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _read_img(path, **kwargs):\n",
    "    \"Read image and normalize to 0-1 range\"\n",
    "    if path.suffix == '.zarr':\n",
    "        img = zarr.convenience.open(path.as_posix()) \n",
    "    else:\n",
    "        img = imageio.imread(path, **kwargs)\n",
    "    if img.max()>1.:\n",
    "        img = img/np.iinfo(img.dtype).max\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _read_msk(path, n_classes=2, instance_labels=False, **kwargs):\n",
    "    \"Read image and check classes\"\n",
    "    if path.suffix == '.zarr':\n",
    "        msk = zarr.convenience.open(path.as_posix()) \n",
    "    else: \n",
    "        msk = imageio.imread(path, **kwargs)\n",
    "    if not instance_labels:\n",
    "        if np.max(msk)>n_classes:\n",
    "            msk = msk//np.iinfo(msk.dtype).max\n",
    "        # Remove channels if no extra information given\n",
    "        if len(msk.shape)==3:\n",
    "            if np.array_equal(msk[...,0], msk[...,1]):\n",
    "                msk = msk[...,0]\n",
    "        # Mask check\n",
    "        assert len(np.unique(msk))<=n_classes, 'Check n_classes and provided mask'\n",
    "    return msk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, files, label_fn=None, instance_labels = False, n_classes=2, ignore={},remove_overlap=True,stats=None,normalize=True,\n",
    "                 tile_shape=(512,512), padding=(0,0),preproc_dir=None, verbose=1, scale=1, pdf_reshape=512, **kwargs):\n",
    "        store_attr('files, label_fn, instance_labels, n_classes, ignore, tile_shape, remove_overlap, padding, normalize, scale, pdf_reshape')\n",
    "        self.c = n_classes\n",
    "        \n",
    "        if self.normalize:\n",
    "            self.stats = stats or self.compute_stats()\n",
    "        \n",
    "        if label_fn is not None:             \n",
    "            if not preproc_dir: self.preproc_dir = Path(label_fn(files[0])).parent/'.cache'\n",
    "            else: self.preproc_dir = Path(preproc_dir)\n",
    "            self.labels = zarr.group((self.preproc_dir/'labels').as_posix())\n",
    "            self.pdfs = zarr.group((self.preproc_dir/'pdfs').as_posix())\n",
    "            self._preproc(verbose)\n",
    "                \n",
    "    def read_img(self, *args, **kwargs):\n",
    "        return _read_img(*args, **kwargs)\n",
    "        \n",
    "    def read_mask(self, *args, **kwargs):\n",
    "        return _read_msk(*args, **kwargs)\n",
    "    \n",
    "    def _create_cdf(self, mask, ignore, fbr=None):\n",
    "        'Creates a cumulated probability density function (CDF) for weighted sampling '\n",
    "\n",
    "        # Create probability density function\n",
    "        mask = mask[:]\n",
    "        fbr = fbr or np.sum(mask>0)/np.sum(mask==0)\n",
    "        pdf = (mask>0) + (mask==0) * fbr\n",
    "\n",
    "        # Set weight and sampling probability for ignored regions to 0\n",
    "        if ignore is not None:\n",
    "            pdf[ignore[:]] = 0\n",
    "        \n",
    "        #if igonore_edges:\n",
    "        #    w = int(self.tile_shape[0]*0.25)\n",
    "        #    pdf[:, :w] = pdf[:, -w:] = 0\n",
    "        #    pdf[:w, :] = pdf[-w:, :] = 0\n",
    "\n",
    "        reshape_w = int((pdf.shape[1]/pdf.shape[0])*self.pdf_reshape)\n",
    "        pdf = cv2.resize(pdf, dsize=(reshape_w, self.pdf_reshape))\n",
    "\n",
    "        return np.cumsum(pdf/np.sum(pdf))\n",
    "    \n",
    "    def _preproc_file(self, file):\n",
    "        \"Preprocesses and saves labels (msk), weights, and pdf.\"\n",
    "        label_path = self.label_fn(file)\n",
    "        if self.instance_labels:\n",
    "            clabels = None\n",
    "            instlabels = self.read_mask(label_path,  self.c, instance_labels=True)\n",
    "        else:\n",
    "            clabels = self.read_mask(label_path, self.c)\n",
    "            instlabels = None\n",
    "        ign = self.ignore[file.name] if file.name in self.ignore else None\n",
    "        lbl = preprocess_mask(clabels, instlabels, n_dims=self.c, remove_overlap=self.remove_overlap)\n",
    "        self.labels[file.name] = lbl\n",
    "        self.pdfs[file.name] = self._create_cdf(lbl, ignore=ign)\n",
    "        \n",
    "    def _preproc(self, verbose=0):\n",
    "        using_cache = False\n",
    "        for f in self.files:\n",
    "            try:\n",
    "                #lbl, wgt, pdf = _get_cached_data(self._cache_fn(f.name))\n",
    "                self.labels[f.name]\n",
    "                self.pdfs[f.name]\n",
    "                if not using_cache:\n",
    "                    if verbose>0: print(f'Using preprocessed masks from {self.preproc_dir}')\n",
    "                    using_cache = True\n",
    "            except:\n",
    "                    if verbose>0: print('Preprocessing', f.name)\n",
    "                    self._preproc_file(f)   \n",
    "    \n",
    "    def get_data(self, files=None, max_n=None, mask=False):\n",
    "        if files is not None:\n",
    "            files = L(files)\n",
    "        elif max_n is not None:\n",
    "            max_n = np.min((max_n, len(self.files)))\n",
    "            files = self.files[:max_n]\n",
    "        else: \n",
    "            files = self.files\n",
    "        data_list = L()\n",
    "        for f in files:\n",
    "            if mask: d = self.labels[f.name]\n",
    "            else: d = self.read_img(f)\n",
    "            data_list.append(d)\n",
    "        return data_list\n",
    "      \n",
    "    def show_data(self, files=None, max_n=6, ncols=1, figsize=None, **kwargs):\n",
    "        if files is not None:\n",
    "            files = L(files)\n",
    "            max_n = len(files)\n",
    "        else:\n",
    "            max_n = np.min((max_n, len(self.files)))\n",
    "            files = self.files[:max_n]\n",
    "        if figsize is None: figsize = (ncols*12, max_n//ncols * 5)\n",
    "        for f in files:\n",
    "            img = self.read_img(f)\n",
    "            if self.label_fn is not None:\n",
    "                lbl = self.labels[f.name]\n",
    "                show(img, lbl, file_name=f.name, figsize=figsize, show_bbox=False, **kwargs)\n",
    "            else:\n",
    "                show(img, file_name=f.name, figsize=figsize, show_bbox=False, **kwargs)\n",
    "                \n",
    "    def clear_cached_weights(self):\n",
    "        \"Clears cache directory with pretrained weights.\"\n",
    "        try: \n",
    "            shutil.rmtree(self.preproc_dir)\n",
    "            print(f\"Deleting all cache at {self.preproc_dir}\")\n",
    "        except: print(f\"No temporary files to delete at {self.preproc_dir}\")\n",
    "        \n",
    "    #https://stackoverflow.com/questions/60101240/finding-mean-and-standard-deviation-across-image-channels-pytorch/60803379#60803379\n",
    "    def compute_stats(self, max_samples=50):\n",
    "        \"Computes mean and std from files\"\n",
    "        print('Computing Stats...')\n",
    "        mean_sum, var_sum = 0., 0.\n",
    "        for i, f in enumerate(self.files, 1):\n",
    "            img = self.read_img(f)[:]\n",
    "            mean_sum += img.mean((0,1))\n",
    "            var_sum += img.var((0,1))\n",
    "            if i==max_samples:\n",
    "                print(f'Calculated stats from {i} files')\n",
    "                continue\n",
    "        self.mean = mean_sum/i\n",
    "        self.std = np.sqrt(var_sum/i)\n",
    "        return self.mean, self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('sample_data')\n",
    "files = get_image_files(path/'images')\n",
    "label_fn = label_fn = lambda o: path/'labels'/f'{o.stem}_mask.png'#lambda o: path/'labels'/f'{o.stem}_mask{o.suffix}'\n",
    "tst = BaseDataset(files, label_fn=label_fn)\n",
    "tst.show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.clear_cached_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomTileDataset\n",
    "\n",
    "For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomTileDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Pytorch Dataset that creates random tiles with augmentations from the input images.\n",
    "    \"\"\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, *args, sample_mult=None, flip=True, rotation_range_deg=(0, 360), scale_range=(0, 0), albumentations_tfms=None, **kwargs): \n",
    "        super().__init__(*args, **kwargs) \n",
    "        store_attr('sample_mult, flip, rotation_range_deg, scale_range, albumentations_tfms')\n",
    "\n",
    "        # Sample mulutiplier: Number of random samplings from augmented image\n",
    "        if self.sample_mult is None:\n",
    "            tile_shape = np.array(self.tile_shape)-np.array(self.padding)\n",
    "            msk_shape = np.array(self.get_data(max_n=1)[0].shape[:-1])\n",
    "            #msk_shape = np.array(lbl.shape[-2:])\n",
    "            self.sample_mult = int(np.product(np.floor(msk_shape/tile_shape)))\n",
    "            \n",
    "      \n",
    "        tfms = [A.RandomGamma()]\n",
    "        if self.normalize: \n",
    "            tfms += [\n",
    "                #A.ToFloat(), \n",
    "                A.Normalize(mean=self.stats[0], std=self.stats[1], max_pixel_value=1.)\n",
    "            ]\n",
    "        if self.albumentations_tfms: \n",
    "            tfms += [*self.albumentations_tfms]\n",
    "        self.tfms =  A.Compose(tfms+[ToTensorV2()])\n",
    "\n",
    "    def _random_center(self, pdf, orig_shape, reshape=512):\n",
    "        'Sample random center using PDF'\n",
    "        reshape_y = int((orig_shape[1]/orig_shape[0])*reshape)\n",
    "        cx, cy = np.unravel_index(np.argmax(pdf > random.random()), (reshape,reshape_y))\n",
    "        cx = int(cx*orig_shape[0]/reshape)\n",
    "        cy = int(cy*orig_shape[1]/reshape_y)\n",
    "        return cx, cy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)*self.sample_mult\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self.files)\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.files[idx]\n",
    "        img = self.read_img(img_path)      \n",
    "\n",
    "        msk = self.labels[img_path.name]\n",
    "        pdf = self.pdfs[img_path.name] \n",
    "        center = self._random_center(pdf[:], msk.shape)\n",
    "\n",
    "        deformationField = DeformationField(self.tile_shape, self.scale, self.scale_range)\n",
    "        if self.flip:\n",
    "            deformationField.add_random_flip(self.flip)\n",
    "        \n",
    "        if self.rotation_range_deg[1] > self.rotation_range_deg[0]:\n",
    "            deformationField.add_random_rotation(self.rotation_range_deg)\n",
    "        \n",
    "        img = deformationField.apply(img, center)\n",
    "        msk = deformationField.apply(msk, center)\n",
    "            \n",
    "        aug = self.tfms(image=img, mask=msk)\n",
    "\n",
    "        return  aug['image'], aug['mask'].type(torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            tile_shape - The tile shape the network expects as input\n",
    "            padding - The padding (input shape - output shape)\n",
    "            classlabels - A list containing the corresponding class labels.\n",
    "                          0 = ignore, 1 = background, 2-n foreground classes\n",
    "                          If None, the problem will be treated as binary segmentation\n",
    "            n_classes - The number of classes including background\n",
    "            ignore - A list containing the corresponding ignore regions.\n",
    "            weights - A list containing the corresponding weights.\n",
    "            element_size_um - The target pixel size in micrometers\n",
    "            batch_size - The number of tiles to generate per batch\n",
    "            rotation_range_deg - (alpha_min, alpha_max): The range of rotation angles.\n",
    "                                 A random rotation is drawn from a uniform distribution\n",
    "                                 in the given range\n",
    "            flip - If true, a coin flip decides whether a mirrored tile will be\n",
    "                   generated\n",
    "            deformation_grid - (dx, dy): The distance of neighboring grid points in\n",
    "                               pixels for which random deformation vectors are drawn\n",
    "            deformation_magnitude - (sx, sy): The standard deviations of the\n",
    "                                    Gaussians, the components of the deformation\n",
    "                                    vector are drawn from\n",
    "            value_minimum_range - (v_min, v_max): Input intensity zero will be mapped\n",
    "                                  to a random value in the given range\n",
    "            value_maximum_range - (v_min, v_max): Input intensity one will be mapped\n",
    "                                  to a random value within the given range\n",
    "            value_slope_range - (s_min, s_max): The slope at control points is drawn\n",
    "                                from a uniform distribution in the given range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = RandomTileDataset(files, label_fn=label_fn, verbose=2, scale=1)#, albumentations_tfms=get_aug())\n",
    "tst.show_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show random tile (default padding = (184,184))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = tst[0]\n",
    "show(tile[0], tile[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.compute_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = tst.files[0]\n",
    "cdf = tst.pdfs[img_path.name][:] \n",
    "centers = [tst._random_center(cdf, mask.shape) for _ in range(int(5e+2))]\n",
    "plt.imshow(mask)\n",
    "xs = [x[1] for x in centers]\n",
    "ys = [x[0] for x in centers]\n",
    "plt.scatter(x=xs, y=ys, c='r', s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TileDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TileDataset(BaseDataset):\n",
    "    \"Pytorch Dataset that creates random tiles for validation and prediction on new data.\"\n",
    "    n_inp = 1\n",
    "    def __init__(self, *args, val_length=None, val_seed=42, is_zarr=False, shift=1., border_padding_factor=0.25, return_index=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)     \n",
    "        self.shift = shift\n",
    "        self.bpf = border_padding_factor\n",
    "        self.return_index = return_index\n",
    "        self.output_shape = tuple(int(t - p) for (t, p) in zip(self.tile_shape, self.padding))\n",
    "        self.tiler = DeformationField(self.tile_shape, scale=self.scale)\n",
    "        self.image_indices = []\n",
    "        self.image_shapes = []\n",
    "        self.in_slices = []\n",
    "        self.out_slices = []\n",
    "        self.centers = []\n",
    "        self.valid_indices = None\n",
    "        \n",
    "        tfms = []\n",
    "        if self.normalize: \n",
    "            tfms += [\n",
    "                #A.ToFloat(), \n",
    "                A.Normalize(mean=self.stats[0], std=self.stats[1], max_pixel_value=1.)\n",
    "            ]\n",
    "        self.tfms =  A.Compose(tfms+[ToTensorV2()])\n",
    "\n",
    "        if self.files[0].suffix == '.zarr' or is_zarr:\n",
    "            self.data = zarr.open_group(self.files[0].parent.as_posix(), mode='r')\n",
    "            is_zarr = True\n",
    "        else:\n",
    "            root = zarr.group(store=zarr.storage.TempStore(), overwrite=True)\n",
    "            self.data = root.create_group('data')\n",
    "\n",
    "        j = 0\n",
    "        for i, file in enumerate(progress_bar(self.files, leave=False)):\n",
    "            img = self.read_img(file)\n",
    "            if not is_zarr: self.data[file.name] = img\n",
    "            # Tiling\n",
    "            data_shape = tuple(int(x//self.scale) for x in img.shape[:-1])\n",
    "            start_points = [o//2 - o*self.bpf for o in self.output_shape]\n",
    "            end_points = [(s - st) for s, st in zip(data_shape, start_points)]     \n",
    "            n_points = [int((s+2*o*self.bpf)//(o*self.shift))+1 for s, o in zip(data_shape, self.output_shape)]\n",
    "            center_points = [np.linspace(st, e, num=n, endpoint=True, dtype=np.int64) for st, e, n in zip(start_points, end_points, n_points)]\n",
    "            for cx in center_points[1]:\n",
    "                for cy in center_points[0]:\n",
    "                    self.centers.append((int(cy*self.scale), int(cx*self.scale)))\n",
    "                    self.image_indices.append(i)\n",
    "                    self.image_shapes.append(data_shape)\n",
    "                    \n",
    "                    # Calculate output slices for whole image\n",
    "                    out_slice = tuple(slice(int((c - o/2).clip(0, s)), int((c + o/2).clip(max=s)))\n",
    "                                     for (c, o, s) in zip((cy, cx), self.output_shape, data_shape))\n",
    "                    self.out_slices.append(out_slice)\n",
    "                    \n",
    "                    # Calculate input slices for tile\n",
    "                    in_slice = tuple(slice(int((o/2-c).clip(0)), int(np.float64(o).clip(max=(s-c+o/2)))) for\n",
    "                                     (c, o, s) in zip((cy, cx), self.output_shape, data_shape))\n",
    "                    self.in_slices.append(in_slice)\n",
    "                    #assert img[in_slice].shape == img[out_slice].shape, 'Input/Output slices do not match'\n",
    "                    assert (in_slice[0].stop-in_slice[0].start) == (out_slice[0].stop-out_slice[0].start), 'Input/Output slices do not match'\n",
    "                    assert (in_slice[1].stop-in_slice[1].start) == (out_slice[1].stop-out_slice[1].start), 'Input/Output slices do not match'\n",
    "                    j += 1\n",
    "\n",
    "        if val_length:\n",
    "            if val_length>len(self.image_shapes):\n",
    "                print(f'Reducing validation from lenght {val_length} to {len(self.image_shapes)}')\n",
    "                val_length = len(self.image_shapes)\n",
    "            rs = np.random.RandomState(val_seed)\n",
    "            choice = rs.choice(len(self.image_indices), val_length, replace=False)\n",
    "            self.valid_indices = {i:idx for i, idx in  enumerate(choice)}\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.valid_indices: return len(self.valid_indices)\n",
    "        else: return len(self.image_shapes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        if self.valid_indices: idx = self.valid_indices[idx]\n",
    "        img_path = self.files[self.image_indices[idx]]\n",
    "        img = self.data[img_path.name]\n",
    "        centerPos = self.centers[idx]\n",
    "        \n",
    "        img = self.tiler.apply(img, centerPos)\n",
    "        aug = self.tfms(image=img)\n",
    "        \n",
    "        if self.label_fn is not None:\n",
    "            msk = self.labels[img_path.name]\n",
    "            msk = self.tiler.apply(msk, centerPos).astype('int64')\n",
    "            return  aug['image'], msk\n",
    "        \n",
    "        else:\n",
    "            if self.return_index:\n",
    "                return aug['image'], idx\n",
    "            else:\n",
    "                return aug['image']\n",
    "\n",
    "    def get_tile_info(self, idx):\n",
    "        'Returns dict containing information for image reconstruction'\n",
    "        \n",
    "        return {\n",
    "            'out_idx' : self.image_indices[idx],\n",
    "            'out_name' : self.files[self.image_indices[idx]].name,        \n",
    "            'out_shape' : self.image_shapes[idx],\n",
    "            'out_slice' : self.out_slices[idx],\n",
    "            'in_slice' : self.in_slices[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = TileDataset(files, label_fn=label_fn, tile_shape=(224,224), padding=(0,0), scale=1, val_length=6)\n",
    "tst.show_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show tiles on image\n",
    "- Center points are indicated with red dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axs = plt.subplots(figsize=(10,10))\n",
    "axs.imshow(ndimage.zoom(tst.get_data(max_n=1)[0][...,0], 1/tst.scale))\n",
    "xs = [x[1]/tst.scale for x in tst.centers]\n",
    "ys = [x[0]/tst.scale for x in tst.centers]\n",
    "axs.scatter(x=xs, y=ys, c='r', s=20)\n",
    "for xsi, ysi in zip(xs, ys):\n",
    "    o = tst.output_shape\n",
    "    rect = patches.Rectangle((xsi-o[0]/2,ysi-o[1]/2), o[0], o[1], linewidth=1, edgecolor='r', alpha=0.3)\n",
    "    axs.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
