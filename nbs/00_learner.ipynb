{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#default_exp learner\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learner\n",
    "\n",
    "> Implements functions necessary to build an  `EnsembleLearner` suitable for bioimgage segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import shutil, gc, joblib, json, zarr, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader \n",
    "from dataclasses import dataclass, field, asdict\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from fastcore.basics import patch, GetAttr\n",
    "from fastcore.foundation import add_docs, L\n",
    "from fastai import optimizer\n",
    "from fastai.torch_core import TensorImage\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.data.transforms import get_image_files, get_files\n",
    "from fastai.vision.augment import Brightness, Contrast, Saturation\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "\n",
    "from deepflash2.metrics import Dice, Iou\n",
    "from deepflash2.losses import get_loss\n",
    "from deepflash2.models import create_smp_model, save_smp_model, load_smp_model\n",
    "from deepflash2.data import TileDataset, RandomTileDataset, _read_img, _read_msk\n",
    "from deepflash2.utils import iou, plot_results, get_label_fn, calc_iterations, save_mask, save_unc, export_roi_set\n",
    "from deepflash2.utils import compose_albumentations as _compose_albumentations\n",
    "import deepflash2.tta as tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"Config class for settings.\"\n",
    "\n",
    "    # Project\n",
    "    proj_dir:str = 'deepflash2'\n",
    "\n",
    "    # GT Estimation Settings\n",
    "    staple_thres:float = 0.5\n",
    "    staple_fval:int= 1\n",
    "    mv_undec:int = 0\n",
    "\n",
    "    # Train General Settings\n",
    "    n:int = 5\n",
    "    max_splits:int=5\n",
    "    random_state:int = 42\n",
    "        \n",
    "    # Pytorch Segmentation Model Settings\n",
    "    arch:str = 'Unet'\n",
    "    encoder_name:str = 'resnet34'\n",
    "    encoder_weights:str = 'imagenet'\n",
    "\n",
    "    # Train Data Settings\n",
    "    c:int = 2\n",
    "    tile_shape:int = 512\n",
    "    il:bool = False\n",
    "\n",
    "    # Train Settings\n",
    "    base_lr:float = 0.001\n",
    "    bs:int = 4\n",
    "    wd:float = 0.001\n",
    "    mpt:bool = False\n",
    "    optim:str = 'Adam'\n",
    "    loss:str = 'CrossEntropyDiceLoss'\n",
    "    n_iter:int = 2000\n",
    "    sample_mult:int = 0\n",
    "\n",
    "    # Validation and Prediction Settings\n",
    "    tta:bool = True\n",
    "    border_padding_factor:float = 0.25\n",
    "    shift:float = 0.5\n",
    "\n",
    "    # Train Data Augmentation\n",
    "    gamma_limit_lower:int = 80\n",
    "    gamma_limit_upper:int = 120\n",
    "    CLAHE_clip_limit:float = 0.0\n",
    "    brightness_limit:float = 0.0\n",
    "    contrast_limit:float = 0.0\n",
    "    flip:bool = True\n",
    "    rot:int = 360\n",
    "    distort_limit:float = 0\n",
    "        \n",
    "    # Loss Settings\n",
    "    mode:str = 'multiclass' #currently only tested for multiclass\n",
    "    loss_alpha:float = 0.5 # Twerksky/Focal loss\n",
    "    loss_beta:float = 0.5 # Twerksy Loss\n",
    "    loss_gamma:float = 2.0 # Focal loss\n",
    "    loss_smooth_factor:float = 0. #SoftCrossEntropyLoss\n",
    "    \n",
    "    # Pred Settings\n",
    "    pred_tta:bool = True\n",
    "    min_pixel_export:int = 0\n",
    "\n",
    "    # Folder Structure\n",
    "    gt_dir:str = 'GT_Estimation'\n",
    "    train_dir:str = 'Training'\n",
    "    pred_dir:str = 'Prediction'\n",
    "    ens_dir:str = 'ensemble'\n",
    "    val_dir:str = 'valid'\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def albumentation_kwargs(self):\n",
    "        kwargs = ['gamma_limit_lower', 'gamma_limit_upper', 'CLAHE_clip_limit', \n",
    "                  'brightness_limit', 'contrast_limit', 'distort_limit']\n",
    "        return dict(filter(lambda x: x[0] in kwargs, self.__dict__.items()))\n",
    "\n",
    "    @property\n",
    "    def svm_kwargs(self):\n",
    "        svm_vars = ['kernel', 'nu', 'gamma']\n",
    "        return dict(filter(lambda x: x[0] in svm_vars, self.__dict__.items()))\n",
    "\n",
    "    def save(self, path):\n",
    "        'Save configuration to path'\n",
    "        path = Path(path)\n",
    "        with open(path.with_suffix('.json'), 'w') as config_file:\n",
    "            json.dump(asdict(self), config_file)\n",
    "        print(f'Saved current configuration to {path}.json')\n",
    "\n",
    "    def load(self, path):\n",
    "        'Load configuration from path'\n",
    "        path = Path(path)\n",
    "        try:\n",
    "            with open(path) as config_file: c = json.load(config_file)\n",
    "            if not Path(c['proj_dir']).is_dir(): c['proj_dir']='deepflash2'\n",
    "            for k,v in c.items(): setattr(self, k, v)\n",
    "            print(f'Successsfully loaded configuration from {path}')\n",
    "        except:\n",
    "            print('Error! Select valid config file (.json)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved current configuration to test_config.json\n",
      "Successsfully loaded configuration from test_config.json\n"
     ]
    }
   ],
   "source": [
    "t1 = Config(n=3)\n",
    "t1.save('test_config')\n",
    "t2 = Config()\n",
    "t2.load('test_config.json')\n",
    "test_eq(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_optim_dict = {\n",
    "    'ranger' : optimizer.ranger,\n",
    "    'Adam' : optimizer.Adam,\n",
    "    'RAdam' : optimizer.RAdam,\n",
    "    'QHAdam' :optimizer.QHAdam,\n",
    "    'Larc' : optimizer.Larc,\n",
    "    'Lamb' : optimizer.Lamb,\n",
    "    'SGD' : optimizer.SGD,\n",
    "    'RMSProp' : optimizer.RMSProp,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from https://github.com/MIC-DKFZ/nnUNet/blob/2fade8f32607220f8598544f0d5b5e5fa73768e5/nnunet/network_architecture/neural_network.py#L250\n",
    "def _get_gaussian(patch_size, sigma_scale=1. / 8) -> np.ndarray:\n",
    "    tmp = np.zeros(patch_size)\n",
    "    center_coords = [i // 2 for i in patch_size]\n",
    "    sigmas = [i * sigma_scale for i in patch_size]\n",
    "    tmp[tuple(center_coords)] = 1\n",
    "    gaussian_importance_map = gaussian_filter(tmp, sigmas, 0, mode='constant', cval=0)\n",
    "    gaussian_importance_map = gaussian_importance_map / np.max(gaussian_importance_map) * 1\n",
    "    gaussian_importance_map = gaussian_importance_map.astype(np.float32)\n",
    "\n",
    "    # gaussian_importance_map cannot be 0, otherwise we may end up with nans!\n",
    "    gaussian_importance_map[gaussian_importance_map == 0] = np.min(\n",
    "        gaussian_importance_map[gaussian_importance_map != 0])\n",
    "\n",
    "    return gaussian_importance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABKkElEQVR4nO29baw1y1Xf+V/Vez/PYweMcw2xrnytMQhLUT6MgCBeRDTygBiBB8X5QMBMRBxk6UoziZQoIwWTSJOJlA8wH0KIJoK5GqOxoyTGQ4JsISeMYxtFkQaCzavB43BBRr5XBgtiO0TOvWfvqjUfaq2qVdXVvXu/nbP3ObUe7adfdu/u2n12/fq//lVdTcyMHj169LDh7roAPXr0uLzoYOjRo8coOhh69Ogxig6GHj16jKKDoUePHqPoYOjRo8cozgIGIvoOIvokET1PRO84xzF69OhxvqBT92MgogHAfwDw7QBeAPBLAL6PmX/rpAfq0aPH2eIciuEbADzPzL/LzDcA3gPgLWc4To8ePc4UqzPs83UAPm2WXwDwjXMfeESP+Qn+xBmK0qNHD40/xuf+kJm/Ysm25wDDoiCiZwE8CwBP8Ep8I33bXRWlR48HEf+Gf/r3lm57jlTiRQCvN8vPyLoimPk5Zv56Zv76NR6foRg9evQ4NM4Bhl8C8EYi+koiegTgrQDef4bj9OjR40xx8lSCmbdE9NcA/ByAAcBPMvNvnvo4PXr0OF+cxWNg5g8A+MA59t2jR4/zR+/52KNHj1F0MPTo0WMUHQw9evQYRQdDjx49RtHB0KNHj1F0MPTo0WMUHQw9evQYRQdDjx49RtHB0KNHj1F0MPTo0WMUHQw9evQYRQdDjx49RnFnA7X0uMIgaq/vzz+9d9HB8NBjqrKfax8dIlcRHQwPKU4BgXOUocPi4qKD4T7HJYBgSXRYXFx0MNynuBYQLAn7XTokbj06GK497hMMpqJD4tajg+Fa4zaBQHu0anM4XzmADolbig6Ga4pzwGCfSn+K/Z0SHHo+OiBOHh0M1xCnAsKpIXCqMhwLi64iTh4dDJccxwLhEkCwJOpyHgOKriJOEh0MlxjHAOEEMCB3upSFwwEV9BSg6IA4KjoYLikOBcIBMDhl5T/kOHsBQ79fB8StRQfDJcQhQNgTBrcFgqVRl2cRKOx33hcSRB0Oe0QHw13GGYGwNwjO7UfsqMh7g+IQFdHVw+LoYLir2BcKCyruYhjchSm5Z2uE/S6zkDhERXRA7IwOhtuOuwDCUhCcK92YqtgLTca9IbEPIDocmtHBcJuxDxR2VOajYXCbnkPrWK0KvgAU+r1PBoiuHprRwXAbcVtAmPvsDhDQmbtYc13xlsBipoIvBkRXDwdFB8O5Y2mFOxQIB8BgEQTckT5EKCtk65izsLAVfsZH2JlmdPVwUHQwnDNOAIW9gdDYfhYE+wJg6dgJU/s1wKjLVYBiFyQmVMSkgtgXEA8cDh0M54jbBsI+MJiqsEf1tlzwWa1oreMLLGyZm5BYoCJ2phhL04sHDocOhlPHkVA4BghNGLQq4ikVxJIIYV5p2GPOQWIPFTELiKXq4QHDYeevgIh+kog+S0QfN+ueIqIPEtFvy/RPynoion9ERM8T0a8T0deds/AXF0ugQG4/KLS2d1RUEiIqoeBcftmy6avexrx0X6d6TR6rLlNr26nv1zgH6Vw1zulB/ow9bw8wllwe/i8A31GteweADzHzGwF8SJYB4DsBvFFezwL48dMU8wpiKRSaqxs/3mOAoOXZUemmKzKd7LUYFnWZd5R36pxMgfdoODwwQOxMJZj53xLRG6rVbwHwJpl/F4CfB/CDsv7dHLXfLxDRq4noaWb+zMlKfIlxJBR2bjuXMtTSf+a95lV3YTkPDtcwCatVzDxOJ+oxFvT9KtUYpRmaOuyTXvTUYhSHegyvNZX99wG8VuZfB+DTZrsXZN0IDET0LKKqwBO88sBiXEDsgsJtAGFU4UsZPrW/pUbmcTGM+ydUsBiBYgoSSwFR+w+NJs5J76HDAcAJzEdmZiLa+0wx83MAngOAV9FT13mmzwWFQ4CwBAY7wDP5fZaqiKlKNdSVqYKFBUXgsrJbEOwAxL7qocNhOg4Fwx9oikBETwP4rKx/EcDrzXbPyLr7F6eCwkxlPRgIUzAo1i8vx/IY8uxIrqOscPZwwZbRVF6zOS8AxL7qYTa1eOBwODShfD+At8n82wC8z6z/y9I68U0AvnAv/YVzQKFhLOb3KnNO11WtCGkfasCRK81A/bwbym2GIZuFg4uvViuDc+1Xa1vZT3H8wRzXDbk8drtW2WGM1pZZac5HsW3jvLbMyUVpXfMPen8NyZ2KgYj+OaLR+OVE9AKAvwvghwG8l4jeDuD3AHyPbP4BAG8G8DyALwL4gTOU+W7jACjskzrsVAnmxz/6vO6zpQwaxxuZkTNexd5R90fQq+tgJH+RUoT0ftpWlURDRcwqiKn0Yod6OMiUvKfKYUmrxPdNvPVtjW0ZwF89tlAXG6eAwpLUYQYI5XYTQKhh0DrGUiNzat1UJAAM5bKGSv4RKBqQ0GI1Uo1JQMylFy3v4RS+wz2EQ+/5uDRODYUlaUO17lAgjGDQOsZc60VrmzpSxTDbBC6v5kAERlIERlUwjyGhvsSMimgCQo+3RD10ODSjg2FJ3BUU9gHCvjBoGpUz5uTUOiBWiOb2XG4DlLCooWHUBI/UQkNFcEiVPFV8hcGEejgrHO5RdDDsituAwhIvwY0r/yQQ5mBQq4v6fQlu+iIzYKg3rdVCOgabz1AGBXNWEzbdUBXRAsQB6mGUWkw0ac7eqTkV90g1dDDMxW1CYYlKaKUMU0CYg0E15TlYTC23wlQKdmbZrKdQrSMeQ8JWsBBictICRK0qXNitHurUYsaUnDQkH0BK0cFwaBwIhb1TB6sIlgKh+LxVFxMgWJpeLAlbKWylkvVsFANZtQCMIVGnAkAJCPUgLCBa6mFXajFjSj5UOHQwTMVchTg3FKZUgoHEIiCYCl/AYImaAMCtc9BqwazqCKU8HmPVYBTDJCSY5TjTgCg9iIn0QtXDjtRil+/wEOHQwdCKO4DCUpVQmIpzQLDqoAWDOp1I+2icg12qwZ4SZrC2TKSrv+yGufIYkCr+CBIKCG2RsICoTco6vQgs5yurh7nU4mxwuOLoYKhjT+l8FBSWpA4tldDyEAwQuJVCVOuYaAwBXZ/Kar/XjvNSN1daGIhyYGglN6pC04daSVhAACUgtGI3/YcqtZCWizuBwxWrhg6GfWJXN9klUNg3dZhTCVNAmIBGgkELBNV6AOCaBXP3T5gKQ4wxDEQ5KChYFUGgAh5WHTQBYTKHohUDMOqhSi2OhYOJhwKHDgYbx6QQp4JCK3XYBwj1+0AJhElA5LIXqsGekqnzYw08WC8xpwsKCwuE+DV5DAnaAYhaZWjFhnoP2osyoPYdZk3JGg7pe5cV/6CmzCuLDgaNS4HCXOqwCwqDa1f+5nIuLxNlANj3ptKK8dkoDchkOOp35hIWgePXZFlvgFAvzyuIkI+r5zWEynto+A7WlJyDwz6doO6ZauhgOCAmhwlrrbedl5ZAoW6GtFCwFb+lEpxbBgQLA11nUoqkGGTSbJ2oYzAKQYGQFEOsGMSIqYWAwkIiqwaAKEwDIgSwQ7zyOzeCx0g9tHyHE8FhFPcIDh0MwF5qYdJs3NV5aSEUFqsEfd96CIOZJ4qG3S4YKAioBIJVFBojz0G/r/JAmxdlXfQXYroAJjAUBlJJ2EDCBxBTVA3OTQMCGKuHoKpAyzwBh1TRTwOH+5xSdDDsmULsev+cUGCjGKyCKCHQAIIzyy0YKAhcqR5ySjF/GtjODCRQQKkSxGdgpgSK5CsEBpNLKoI8TwNC9luoh2heRHB4NR6PhEMdS83Ie6IaOhj2iMW+QuPuxYOhIMspdXD5s+xcShPSvHNtIAxUwIAdChDEqRa2kU7sYqQdbUnTBFCsBywVSEERUEIiIKuIEI9dAAIuexBmXg/GxCAFwuBKY3IhHNLfTeGwhxk5PhnXD4eHDYZjUgiNXVDQzkv7QqH2E2zqoF6CKoPBbmeA4LI6iOvkQm0VhbwSNJxZBjIYdqiGdCMlm2WdD2VjAoUKEmRUhOcSEF4qZwiiGBrqwYeoptgAwqX/puGQ/h5h3JSpf8sHmlI8bDBMxdIUYgoWNRTs5/aFwjBen0HgCjiwgMMqBHalOlBAQOYLEGhKYWFQpxVTpySBQT0GikqBY4Uk5qgQgi4LFFRJeNkHIQFCUwxtUSBJL0ZKAsipxeBK3wFy/rxvG5KmtWIEh2P8hitXDQ8XDEucdt10KoVIu6rUwmg+g+AgKCgQbLpgVELcTiq9AQJEHbDCQtXDgDKlIIxSitpf2AUGQFUCmXmdcgEKcFQRFCCtCfJdakBoikHyQRfTC4ZRDx4gp86jK30Ha0oOwzwc5O+U4BD/sAUcir/nEoVwxV2mHy4YpuIUKURtNu4JhZFKaKUOAoekEpwqCaT5AgiiDhIwnIFBmrfTnEoUUGidDps+yDIxGxBQAQoKDJZKSAyQR26CtIAgAhHHyuuRWx1UPcCl1ILgUPgOCGM4zDVlhlyJp8zIXX7DXinFhauGhwmGPdRC+bmJFGLObJxKS3ZBQU1GA4VR6qB+QoKAVPLB+AsGCEkduAoGbpxKTCmHyRh5C1SqAwMKCqIeAoMCgVych6cCEAicgBAzDKMeoBXcJRVBHvE8+hDPWw2HOc9B51tmpJmfHMdBT9M+KcUFx8MEw1TMqYW5FCIuxGntKwBttTCRPuyCQjN1MIqhAMFgwYCsDgQKY/VgzUf9XgvgYKDAspyGVqhhIECArIspBSM+vzMDAsTRfCSU6kGKwSIDiCkBYBEcmHYrB+s36N92LqU4tPJfsGp4eGA4VC1oTKUQo/kdKUSCQJ7PaiGnCtZkTFBogaBWCQUUDBDssgVB4TVkBTHyGHalElU6YVskoKlDUgxGNQSAiAUA8p6X41n1QHE/cd7FfghwBRxSi4UPCYakX8BAI8EBjcqpfsMpUoorVA0PDwxTsadaKDeeSCF2+Qq2n4I1GlUp7ILCMKEShh1AcCUQilSiAsROMNjfv4IhKQabTrCBAcw8jQEh847G6sFtczFs1bRwkLbOeC6B3FqhTZkW6t7nPg0NvyFtt2dKsTguVDU8LDCcWS2MUoji0A0opMpPYyi00gdH4FWZOoShVAmhhsLQAkQGhYVDbsY8DRhQKAXK6iGwtEjE+mcB4TzLeZEGCaseAIRVTi0cwiQcUlrhCNpakYFAxsik/VOKyT/y/VENDwsMU3GIWmi0QsT1bbWQPlOlEkXnJaJJKPBQ+glhlVMHnbcQCAPMugYQqnWFWnBjEOybSozBgASDUhkgAcJ5IFDsIm19BSeqAdD0hoBtQEBsncA2V7gRHIyCSKpBmzdbLRW+/jtXKQXwIFTDwwHDqdVCtc9FKcSOZskMg7FSaEEhphI5dUhqQaAQFApDBoLON8FgFMNsOlGf2txKODYeA+Kdl6MUQgDhMyBCUgeSNoh6CGBRCJJagIGVEyCQmZfyNOGA2ENSKno8AAozMsqZBSlFy4hMB78fquHhgGEqjlEL9Xxr9zMpRFqfTEcIJKbThwIKKwOAFhwEAppuhAEjINReQwYD704nZtMIKu+LUBiIgkjLTkCg5mPI6QOIQF6g4OMFXk9TGvllCg5M0m8qT/V8s7RmyB+o+Fvtm1KcTDVcWHQwLIkj1EL8/IyvIFPbaSmpCZeB0IJChkANBwsGk07YqQKggAQXigEE7ZIwqxpsMyVYNtVRm0xLRPYT4nbOIz1MKk5JprEFIsi5dZ6lX2NMKQJITMgSDjRQZpWj1KwZNYcrWipGfsOuVoq033FKMT4hB6iGC0snHgYYptKIE6iFScOxlULM+QojOCBDYCEULBCsSrDqIb2SeuCsFozpGHtMGtUAjOCQx2FAoRZYFUPI6+L9C8j+gs+pQ3DVsnoLBAGEJAUU1UVKELaIBxO1EOCyITnEqz5pgfUmLUel31CnFFOtFA9MNTwMMBwTO9RC2qY1PJs1JusUouUrkG1+bDRJ7gEFtkAYkPwGJOXAGRaEAhI2nUhqIUEh//B1Tu+DAFAMrJLTiNz9mdVYdOovQIzGnEJEIUUIxPniTnH7tnvAsUco8o1acKIWOIAHmvYb6pTCtlLURmT6e++nGhbHBamG+w+GQ0zHY9RCa2TnWi3YtKL2FXQbA4PUJGmbHgUGYUVl5R/qZZM+DAAPPFIPKFQDi3Jg5OHlGbVqSMEivUUlxHUcL//GW7DNknACCAdpcZD3XUwvoOre9FaQul5CgRlhlap6OjQGLTZnKGgrgvUb6pTCG1OxZUQeqBqu0YS8/2CYiiU3Sx2iFux2lbdQj9NYpBDGV8gtECibJEcKYQyFsCqVAjuYdRkAuqxKIYJHFYJAoVAMPMnYdJFT5SDjLSgckJokTVOkl+/lOBmQqAzGIJXYteAglR6IoNNjx3lTHiD6HQO1UwrbStEyIpeohnsYDxcMx8RUS0RLLei0aInQVKJMIfINTiZ1cHZdO30IA8Ark06scurAK6MSknpQ1cCATgUOkHkSj4EEDqnOEI+/N1NqnmStoEEqogABQa6kQSqj49gakU4Pw1E8B9hKRybKIIjzYkIKAFRVxHV56Di42OchwgDRT7AphT7JKsGA899lX9Wgv4fWaE+H3Hl5IenETjAQ0esBvBvAaxFZ/Bwz/xgRPQXgpwC8AcCnAHwPM3+OYq34MQBvBvBFAH+FmX/5PMXfEQvTiDnTsdnLUdcfoha0d6MO3KoVnwwMRl6D8Q5cAwq6vKpSiAEIK5M66PxQAUGUAykU9IVYYcmpXB6rhjQwdIIDIbBcjQUKCQw+rovwkVrvEPsmOIinIKmB9nREzmjysXJKkYA0CCBMS0WEhEkptAkzqYcjVYP+reuKvMSEvPB0Yoli2AL4n5n5l4noSwF8jIg+COCvAPgQM/8wEb0DwDsA/CCA7wTwRnl9I4Afl+nlxK57H4Dc1Fh8bgdolqgFm0IoQBylFCL3KaDkKwSTWoz6KVTpQ6kaWPo6lFDQFAJDhAINQWCgIAhwjuFEMegVnVpqAQqFCAadDwKEwJTgwC7CIaoGQAeOIWJpbQC0OVLVAjD2FyyMwsBwLFdq1n4ILCNDIfoNmuI4GW2aKYEiez+Iy1Y1eG9+Lw3VsMSEvNLYCQZm/gyAz8j8HxPRJwC8DsBbALxJNnsXgJ9HBMNbALybo6b6BSJ6NRE9Lfu5zmiZjrtaIlpqoWU4avpAKFWDKok0bzyDVuvDqoLCikeqASuFggJBoDAwHDHckIHgXGzqcxTnlZMtODCTPNYhQsEzIYQ46rP3TiDhEFQBeQd4sQJI1IOICm0/iAYkNdQCITCngZccU4SdjDqtfkNsHRGFIymFdt5IRqRzCRQxbbDpRfwbiYsx//uYMyGvNJ3Yy2MgojcA+FoAvwjgtaay/z5iqgFEaHzafOwFWXeRYFiURsSF3fuaUwuyXKiFkd/QSCEEEMW9D40myREURCnEeUkdRCFgJTAYpNILEIYhwBFjcAGDi9OY+3OGRAWGIAZf4Ni5yAeHwAQfIhz8EAQODO8JwTlpFnURmFsyPSpjNUxAYKsWUMKA5TuxpBaDeA9MwBCbSuPDbuN+EoDSU7DEiwj2b9TwGmy/Bm7kFMcohQtOJxaDgYi+BMC/APA3mPk/2UrDzExTOnN6f88CeBYAnuCV+3x06QEm1h+YRgA7Tcdim5bvMKUWnIKiTCEK09GVfRVympGVRFzOnoJCIYJBVMIqqgQ3RIUwyMsRYzX4BISBGCsBw8qF1DIwqRgQ04YIBQev0+CwJYbnAOccvGcEcggudmRicsAWpiOVhUM0EbOPIFOOIHLMKb2K8xEYUeZT8Rk1IqOvUBmQ1mtId3caFWGbJxeYkPchFoGBiNaIUPinzPwvZfUfaIpARE8D+KysfxHA683Hn5F1RTDzcwCeA4BX0VN3b8NOxb6mo05lvkgj5L2RWrBpA9VAMH6CLleQ0NaHpBSGBhRWDBKlMAxRJaxWAYMLCQjrwWOgOF2RgQIxHBhOHh5hVUNWDA5bdgkMWxYoBIfVQNj6AVtibB3DO8Z2G2V2kBQKW2cEewkHbelILRKpBcTMu5xSsPgneXh65GHhKtUQPQ6jGhQEAgv9m+9jQp4knbjjWNIqQQDeCeATzPwPzFvvB/A2AD8s0/eZ9X+NiN6DaDp+4Sr8hbk0YlfUpqOrADFKH9DwFoxaMACox1YY9Wp02k9hRikIFNyK4QaPYWCsVh4rF7AaAh6ttgUQdLpyPqUPqwSF8RUxCBACCFtJJbY84MYP8BzhsCHG4Bycd9jQACLGdhsREIhkeAQDB232BKKnYPopBLFJoqHJ+ZxxPneQFghVViPVEKSFIqUVRjVYz6FlQtaewznSiTv2GZYohm8B8P0AfoOIflXW/W1EILyXiN4O4PcAfI+89wHEpsrnEZsrf+CUBT5lzHVqKjecgUTxRCozP2E6TnkLcBNqoXqlSlA1S9ZNkhjQhMJqFRIUHsl0PXg8cj4B4dGwTWAYBAqOYnqRvqpc0QFEs1HgsHFO1IPHioYECEcM5wfoPRA3clq3pE0HIcNBfQGoZ4B4lRVTkew50JRCzU/HkkbE89BUDaoSxGNo9oa0nkNtQqrncI/TiSWtEv8OaA7PAQDf1tieAfzVI8t1XBzjL0zFVGtEfczacJR1Vi3oMqcfK8z9CgIAqtRCnUIUaYaohbr1YWhDYT14PFp5rF3A49UWaxfBoEB4LNO183DgCAiElELUqURggkdWCp4J2zBgRasEiJuwwooChjDgRpo+N9vBnGCBgyoDgUNueYDxF1QxGEhUL/UZ0nnVPhgCh6K5UntDjv7mFE3IYvnA388FG42t6D0f52LHWAsazTRCl/U9l5fzOAcZCsV9EtT+sec7Io16aHRz5sJobEPh8eDxeNiKWtjikUwfOy+g2GJNMZVYk8dA2YAcTDrh2SGA4pQJGx6w4QFbURwKhFUIeInWIJ9bOepgDLGHIjto8yJzVAupOVLvtdDvGxDVVrrfI6sGCqIaAqJ/w4idtYxKSB4Dsq+wM51otU7o3/uQeycuMDoYgHl/YVcaUbdGyGdGacSU6UiUu0MPSC0TLbVQ92cYd3M2/RRWAZRaHbgJhcerLR65LZ4MWzx2WzwetgkIa4qAWFNUDWu3xWBya0cBgeN39oiphGeXwLBxA7bB4WUKeJlWcKQm5nrU5AkgpQKx52SEQ36+pfSYlJSCQnku9LF36WXAqsqBQlQN6uMQc+ExNE1IBYb+DuZaJ+5JCqHxYMGw2F8A2sphR2uEfS891Ul/tCaN0LShGIi1+nGrOoB9T7o0W0BAFIV2XtImSespWCg8GTZ4Mmzw2PkIBreRqcBBpoO0SNh0woamEhseEAQOL4U1NiTeAgU4WiWPwvmyArGkI7n35BCvqHLF1xGftMdkWlecH1EKCtaQ54kUAiTph/RfEBMyqgVMpxO2dWJXZydgf5/hAg3IBwuGfWPkL9j1ccZuPJlGxPeRYWBNxwQMkx8XCqJOI4xacPE1hkJIUFi70ITCK4abBIQnboPHbpNVA0V/YU3bVLEHmFQCsc9CgFUMK6zJ46WwTvtwxBkMerckx1vKY8uDZA8slXpggQOJUgD0IdWsXZ6tp+CAcQom+3K57rVMyJ3pBFB2djrUZ7iiuH9gOJXxuNBfKD9D42Xtz5AgUaURlVJoqYd6nMbWyEtRLSgYApyTNEKaJFdqNIqXYKHwimETgUAlGB6RphUxjYg+Q3llUyBoOnHDAzbsseEBjgJeDuu0rQVK7BAVHxLBTPBDkHsfQuxCzYQQWPyF+B1Jz5nCoKGwFBD1S59LkUxIiZROBNmm9Xetr9z7+gzF564j3bh/YLjN2OUvmHXpvao1woKgvuKlZWqsk/VwtVrQ7s4RDKvB45EAQU3F6CmUUHilu8Fjt8ETissKhEcGDA6hMB4BMR8pgsGzw5pX2LDHDQ9wzDkNGX0uqgVrXMbOUSGqiCD9NQJJzybKV357jtguk/gICt12OoHUu9F4BlXz5GKfwfJhKoVoGJCXHh0MxxiP5Qcb24z9hVFrRPIcqFpG/oGbq2CrT0NSCy7mz/HGJ5b7HqKEf5SaJH1KGzR1UCi80t3gCd3gEXmBwxZrxBYJTSkAFCakJ22qdPBEBgprDMzRl6iukh4Orxhy34etc9g6l3phBiZ47+LdntLCwEPs+sgyLFxqedDH1tlzVCkwhQWZ81v6DPKkqymfwfx9Rz4DGQNyDz/g0lsmOhg0pozHVkzBY3Slqdab0MfXl5K3XkYJhPSD5yqdyFAgh0ItrM3rkbQ6PB6M0UjbAgpPRDWoUliTxyN4MR+5gIKGBwkUhkJZvBTE1DODKsS0Q4EwyNTDO5dejmK3bQ6E4ChCT2HqjPyvWyI0najOWxxrQV5ASi2Kzk6qFozPkP52dX+GJXHlrRQdDLvCju24xHi0YbyEuK/sLwD5t1f8sO0Vj1CohTJnVtXAcsWMzZTUUAtrJ12cKeCx0/4KUS0oCCwUFAxPaJNaJdZFP4Y49XqfBAgelMDhKGDgUEIhQG6ecqnr9ONhiw07rJzHeoj3V2xCVA7euTRgTB5hikYwqCGgFT4rLy5UWPIZRn9njHyGdFOV+S2czYC8MP/hQYKh2VS5K3Z9pmU8Fgfd7S/MqoU6t9b3HeKVL428JLdQu2g8rgdpqhyiUtC+Cbl5MsJBQaAewyNoq0TAGrE79DqBIX4lb8ZiLMCAkI1GqXCeCGsa5BWPv+EBj53H1nnpKRmwdgFbGQ/CWTiQUUZy7jSdqJVCoRqKv4HABDDnn/M687caxT4G5CnjjposHyQYdsaSFomJeyomjccqklowPkTZx6GeB3RQ1iKPplxZyAyyompBlYK+ig5M5qVweCSpwxPaRihQwBoMGagathPzOgEC2DBjkM5Q9j5Jzw6etnjipEkT0ajc8IDHvMWWB6ycj92u3ZDHg6B4u7aj+DyJUToBFGqheKE+Z5I2QJa1P0PhFejfzZiLxd+wYUBOxR32PzhVdDAcGzMQGRmPQFYJKH2uwvMyufDkj90xitGcZYxGJ9PBBTOeQqx4qhbWLndeik2S+aXpg4XCmoBHlEdTGsz11YPj/VpgbABEPZ7L/MRtEIJDgMOmAaSVHGsl5VWloykRKCsG9QSaZmP1ouqcJVXhjWpwKAxIpHX2bzVTyS0wJuJamyw7GM4VTTlq5tOt2fqi4oc+m1rAbCP70DEZifLIS3Y8hSGNqcCjyvmIPNaw68ZQWIPg5DtZMDhwvC2aECsQAQqHAEKAx4a28IipxCMa8DLWqdNTeonSWFEQsGW/JIga4uocFRBoqIZivv4btIVcD4mHAYZj7qpcsr/ZZs3xe0lJND6WU4zWvlovTvPk8sCtzg6yoimFufch+gEhKYWBAh5BjEa0oTCA4OAwSPm9jr2YjMmQ4OChlT1gDY8Nr5L/sKYtHK2KezLi2A95cJibBDr9jppCSUsC7PcvT5Y1IEfnrdqOTIqQjMc5MxkomyxrI/Ke9GV4GGC47ah/WHa5YkrdIhG3l/eo8Z5538IhN5BwagW1V2G912GggLXbwlHIPRrBcgWPSmGg6ClYKKwxYKAIhvRVSEZR4Ki/AyiOEs/RqPSybpMAFBXDS/aOTVELg1EPdpxJsi0IKZVQGOaTUigI2GlD7pt1LPuhepv45ZYFxZ5Oo7ThiuN+gWHuyn3u47X6L9ioTMmpfjR5f+NVLXjYYtgh3vPYCdIpyUh2VQsRACG1IgwCkjVY79lKSkGh4EYFk44CHPsfrDmqhXiLgxxPekBq70dtsXBSDieKww42S9X8KAWo4FmUaqQM7HwDAsVnGyCJJ3K+L8OVKYJdcWKNfY/iFJA55OzWyqAhg3O6YStMrRosJMaXvgQO083Zdl6yrQ8u/ROPgVx6OZNeDOl9KvZnj6/do1sdpeqBYCzoWnAY7aFOF6pzxvuAOR50wUb3MzoYri3mPIhG2NuknSqE6sod53PnJe2nMCCrhbRdw69RYDi4ZFDmFowMh7rnZEolqjL2uPvoYHgg4ebk8xHRAsWSaKmY8n3bxNdhcdvRwXBtoSb6nnUlGF2tIy+1wjONUmk/Y6h5DgipB2RAmNg2yK3ZXsphyxCYRvOBG7lTj1uL+2U+3sdgzPehMe/ZOtmqYIHjLc4aHi6Pp9DIp3OTo47hnDvnDOTgTUedGh7aTdo3XFQtg95uXZc5fx9qzic4jvZcxbFC4560MBwS90sxnPIPuWRf9TbpCSgStVo2701e8dlMuVxPlVogqSz6lOk4T6kSMeers5fxDvSGpwgJGQvBdFWOnZJi03xAfKZDQICXqaoDVQrxFf95cHwxwzPyMTmP11CME4l8y3ZABlmovkOCgj0nrUyD0QRp6gax6PxPvLGrxeEetUgAXTGcLnRE4an3Aue2cWP5U8g/3Lz99GGI5e2qEhRPmmYkCKSHwcjtzlo5k1pIoHAytgLJvQx6p6T6E9JfgULBOwWGlx6QAcAGAhXk/VkA6diQaYAWkIGIfocSEDDwg1k3VcEzPLlav7AC71PRRTndlz4MQAfDYcFV7R69v6P/PDNY+zYX60tVUL/YwiBdJbVnTxYszDqOIsXHxiFXNE0nNjxkSKRBVobUcjCQj/c+xMdGx8fFEccHvIjQVEQoFDZg3IhauGGHjRkDcoNBhn0bSnXCCgVXQEG/AycQUvreVENidK44ncO5vw/JKNRUK70dcRAArkxRPAww6JNJzrZ/xrhXDU+/B8QfymCvhpx+7E1VUL3I/pYFBtAKxZSeOh04jn2wcQ5bHdrdjOZ8w0Maji1BId0hGaT7YOywtGYgIDcvqtHoEZXCDTM2DGxA2Bg1clNBaMMDNmGFTZBnUIQBW47lyxDLCogDJSiSAYGdjoFppnPvm6Dib9aI1vq6wl/x4Cw2HgYY7iiSMoC94lcAqH9rrR9wrSKgF3KSNCVWFr3SqizXp02nVILzA2HSlZx9Ho4t9UKUex8YUDh4jv7B0Ljb0HO8s9IrFIxaeInX2CAe66aCks4rDLbyEFzPFO/INECwyqhUDqVaaJ3DOlUr07a6Yi/607Y/u+gz1wGODoZWhLB7TAa94ocADDmtIBmuvNwWI5tXVUGWs2RkMDV/9MlklOc4kkCB9QlNTGmEZR8iIPRKvOU4GMqWAjZuSEO7q2pwvI49EtkMsiK9g710kw4Ux11w1VfzDFEMDhtUUOAVNrzCS7zGS/woTsPawMlhE4b0MNwCZsGBg4tqKOQDJpWgz5etYFG/8t8GBhZs9tkgdM7Lyvf2NKWv1XfoYDhVBP0l6lWcIwyMPCVVC8ljkDRjIk0gzo+AH/3w9SEsSTnEwUc4RDgEqWA+ONz4ASuKz5JcOS9Pn45wcBTiaM7MeYxG+7UQH0Xv0R7z0atxKEpBB2GJIFg3QBBfL4cVtiE+0/ImxIffbkJ87qUPkk4I5BD0BQEjzauE0YtLFWblf0s9tCrzCBy3dOXvD5y5vdAHlizenjlebVxpOjJzHPdxqkUiXf1zSpHfK1OJ4oeuEAjV1c/CQD+f4CBQkCut5wCfpHlWDTdhhZelK/KaPF4O63RTlR2j0bOLg6xI+4UCAqhGiVYDUYDgQUkpKBR0+nJ6rRIcVC3c+CGrBU0jQoZdPB+UzokuY3SO2CzX81ydY07nPomku7rCX1iK8SDB0AxtThytr9IKaxq2otWXQZWDPqY5xOHLtWVCn72o/oP++FN+LU9hwpABEaEQt1Uo6Mt7gnNxaLTVQKniRdWQnyW5pjiQQFQNoRi41dMWIThsZAj5DQIG5mZX5pCUgvgI4ilYKKSpgOEmrLBlhxtRDZ4FYuIxeC+tFIVSQPq+mhak89FIK9qmo8Kg0SJRpQxUpxhqLC5pYbhyE7KDoWqxSCogLkwrATLzOrXbj35wNDYg9VFr6YqWfQZSuRzMelEM8crJWUEEJLkd4eAQAsNzwNYP2MiNSjdhhVUI6VmS2rqQHgZjBm7NYzSSPHJOHmrL+T4H21nJs8MGg7Q6rEQ1DAkKX/SP8TKv8HJYRdXgV3jZr3DjV9j4ARsflcPWuwgFAzoEAnkShUBjGCgkQgnOWm0VrRhVFC0So5aGvNz0DK6sKXJJdDAcGrv6MkikNGLKgJQrV+0ljH7w5qUwyLAQQ9LHwWiDK1XD4Bycj2rhJVqnod4G4uIOSyAO8b6mwYzROMhALkO+PTs1U0YIauelG2lluOEBL/EjSRdEJfAKX/SPBAzx9ZJfiWIYsAkOGy+qwcd0gj0B3vgLxXnICqKo+CPlwNU55Ww8KgS0sttTscR0DJrLCTD2UAmX/LAZ4D6CYfIqv2dfhkNaJsSApMBxrAQ1JCW/5dqA5Kwimlc5rfgWEpwrhj4SnuThrxxg4ODgPceh2L2LY0GGAeTjo+hb4Tk+92FNsRNSHA8yNmM+oghBvX0ayGDQnpTaaSq3SBgwCAz+i3+E/+LXAgXpy6CKwQ8RCj5Cga3paP0FC4kCnGxAynn9lL/AZn/pb9MAwkSqsSuSulAIXJiPMBf3DwxnioMNSGDeZ9BK7iA/6lzZk9lm5ourpo/7JY84bL3sl70DO47PlHQsj6MHbsgMvurzA2QAeWo1Yp+CNXkZvNXLwK1bvEQ66lP549YborRHo/ZN0JaIrBDWAoYIhZe8pBPbVWwl2Yr5mNSCS2qBfHwUXZo2IFEoqxquPp9bpLTtQH8BmK/gV9o8WcdOMBDREwD/FsBj2f6nmfnvEtFXAngPgNcA+BiA72fmGyJ6DODdAP4sgD8C8L3M/Kkzlf/gaLZM7GNA6vDlQPsKY16qFiIMSp/BphPRhGw0X9ZphPzY9fmH5OVZjPLgV3iAnUNwwHYbR0G6AcrxE/WrpHQgdzLSh8HkR9ivklFpB14pbohSA1JaHFKrA0dz8WWf0weFwsYPuPEDbrbiL2yjWgieUhpB9iUgiHCIL5fmjUJI88vSiNG6+jcxt9yKUxmPdwiZJYrhZQDfysz/mYjWAP4dEf0rAH8TwI8y83uI6CcAvB3Aj8v0c8z81UT0VgA/AuB7z1T+08QhBqR+TtVDCLCPP0rpRN5pmjbTiSJ/tmoBohLyOuejwo5wgKgGgg7UyIiACfEpNNhuY9E229ITiT0itwhM2LgBWzfIY+Piw2B0iPc0cKs2VxrV4KXnok61m7N2dX5ZWh9e9quUPigUXvYDNt7FNGI7jKAQR5Y1IPCA8+V5sQqq5TGQwECbMUdpRPW3aXZskmlhPKq/EPj4TkwXmGLsBAPHb/2fZXEtLwbwrQD+B1n/LgD/KyIY3iLzAPDTAP53IiK+1i5gu6JuvrQdneyypg5y5RqlEzKYaFQOZQqRoCEgsBBxnhDkITMwz27ElsDkIkAAbBt3FAUpt73JasMuPjaOB6wMGJwxKu3oSrEPgzOf1y7PLnkIN2HAjRiNmzDg5e0KNwYK3jv4bUwj2Dtg6+K52Rq1oKmTUQwttdDyGGxvyVEaYf2FVtSpBgc0r+RTKqGhMC7deAQWegxENCCmC18N4B8D+B0An2fmrWzyAoDXyfzrAHwaAJh5S0RfQEw3/rDa57MAngWAJ3jlcd+ijjMZkIXPEFwCwshnWJhORNMQedhxplT5J1WDp3j3tngLINmeEKU3SUpBALYRFIEIdQtKvnsxXu3jo+jj8x10utaOUE4ePUclGPJgMKoaCNswJOVwo52XgqQNITdL3myHBIWtQmHrwFtJIbbGW1AY6DIbSBTnp2E6qlJYmkZYf0Er8NL+CwYYo+vgBaqCuVgEBmb2AL6GiF4N4GcA/OljD8zMzwF4DgBeRU/dCUL36gHZaqVIzQVDdWWp0gnTPTq1TvgAJpdUQ6zkJEMexHI1VYP4DOSFQUEqDHFOKeywBVsn1/mc9sTffLyD0Q8hegvyCPr14OIDZl18GK5DfMSdPsmqeWqQb53eyu3T2xB7W954aanw2iQ5YJM8hcEoBYpQ2Lr4HRQC29p4rBSDZ0kxqlRM4cEWFlrpjXF5SBqRvvgeyuHKYq9WCWb+PBF9BMA3A3g1Ea1ENTwD4EXZ7EUArwfwAhGtAHwZogl52aFqQgzIxT4DMNlsWXxG1EJuvtQ7B7k0IaXJMaqAhq9ADEck89Bnncg6fTIUkB4ACyAOEg8AId7tUIx3EFMAffT8lh1WFDC4IYHBmdGc61Gc7RBycfyHfEPUJgypW/ZW+ylI12c1GkdKwROwJbitQCGpBWQA+LFiiOeoNiDlfFZqgXwwXo++Z9SC/ZvZafo7Mg7tvzCKKSVxx5n3klaJrwCwESi8AsC3IxqKHwHw3YgtE28D8D75yPtl+f+V9z981f5CSykEPiKdQPyBkvmxeo4pQa0aiNIPPhCVisG48gGInxd/gfS2SJEOCQ5MIA6AQImZEIYAHwJWg4d3DpvgsNbnXbr4hGyqoDBOJczIS6Cya7PMb03nJe2rEI1GVykFkzYoFBQUI0iwaaHgctpQC4XpWHkMRUylEQubKUf9F+xmV+AvAMsUw9MA3iU+gwPwXmb+WSL6LQDvIaK/D+BXALxTtn8ngH9CRM8D+I8A3nqGch8exwzaEgLYuawkgHE6YVsnuNHZKRCIZD9eHtQ6pRpIftBEyV8ggjwantJhSPyE2KM53uwUajhwXGR2CBzAPIADxzsxh1ixFQZbx/mp00B6ajbQfu5DPRxbBoLe0EUlEIJpfdi6QimQB5ymD1szH1CqBuslFGnEtFqI51DUgjdqYd80QlojFseV+QvAslaJXwfwtY31vwvgGxrrXwLwF09SumNil/zXzWb6M+ybTrBDVg32tusDVEPsQQmQNCuopxChYVIKCBBWuh4AZUhEGpBAAQkOHBg8xObSeOOVwzDEdMK5gIGkt6Tj1DGKDBR0mLd4auxYjYgVX0Eh+9ZbwVlVgmmSJEkj3NZ4CQ0o5DSCx5CwsEhpxoS3UKuFlumokK9bI+r7JmwacU/8BaD3fCxjSk3sap1odXZSE3KharAtFAiyzqs6iOudj3AKkHFlieGQ/QbAAIGRlYP+lhmSRsSyRMXA4AHSDBqNUL3Hwsmj6LVjVA2H+DVzOpE8i2BGYJJbwTlQ7uZcQYGs0RgqKHgIMMzLphSBKwXB+eU5ndfCW9hXLRzSGrEkjbhQfwHoYNg/pu6hYOM56DZqSu5SDbaFgri48qeUQsxM8qJidBvEZR1KAYCZj2lFqrBSBGKABwByv4UCIThpIXHiJyQ4oHyGZP3V01iTyFMZeUnHU0hAMHdLwrY2GKOxBYU0rVshqtYIt1XVoArBgIIRldmcWgB2m46tTk1TauEK0wjgvoNhSv7XPR1tOrFP68SUCWmPLz+gSdUAl1QCpMlRO/HYlMJ5QlAI+KgE8kNs47SGQzIYmYEBcJxBULSyBqR7LVjAEAhpClEMBRRIUhRk1cBAGlRFR15KxzI3ROVuzpXJaJsnwxgKNoVIkFAgeAZtMUoh4rhz+gplS0TrZdMI/RtPVe57lDrUcb/BcMqwSmHOhNxTNRAzOAiMVC1gnFKAFAoQX8GkFclsNPdqAdBuwQkIA8xVXH7v8Vn34EGg5zjWd5mS08QcYnS2U4mcpsRpgoEsk8/rCiAkKFCGgDUaDRSyasi+grOwsCkE51RCVUNWCSggMKUWprpAVyfAzN6PNAJ4yGBY0jpxiAmJ/VRDVg8s3aQRYWBTivhpAQCyr+DtaGwsv3kDiMECQitpVA/p6u0Qb7wKgBgJYMdJrbD0h1A4cOurF/s3G6l5WkwFAmx9AzKV21R+PwEFP+UrIMPAGo7WU/AMCgHwIZuLu9RCVVkXm45XmkYADwEMh7ROLDEhVTXUJuSUarAtFEEdAEDsw2RExjfyFdptpcXB+A3Rl8jNkmUKwclPgLCGB/P7V19BumUzSRdtL4DQV5QtACHCTAHRPHl5qs990OHYcpflfKu0tho4r6kFTE/G8uXqFgiFgp1uq1YJk0IUhqNJJZJym2iJaKqF0fdephauMe4/GM4R+6gG7degRqNUylFK4TnqAUkp4mfjvpLfAE6tDhkKMi0ufBzTB/ObV9sELl69eUAGhEO8hZtkXqZQA1RvzALGcEhQyEPe5y7H5lZpVkDE4xetC4V6MF2dw3hdCwrJV9hygkKRQuwyHKdaImq1oKbjnmrh2tII4KGD4RATcg/VUPRrAMxVCvMpBaIpWfgN2wCsIjTctoIDs6QN1meQfgaqGlyeaupAMn5DfHFOKyg2Pca7NYUFConmedRpAw4ChNQnI9hlAwdrQIZaJSA3SxooZOVh/ASbSmgKEUKZQswZjjMtEeV3vpxKfI54GGBYmE4cvU82cLD9Guw9FBCwTKUUcDpgGkDxtqU4fLuLcIjVPsOBGTxkEzKlEQPie5o+DHIBHGBgkNVBbJUQq0CaKGMagawakBmgkb2UPC1VAiU41MOxQdKHcsoVJGzX5xIKERICA9+AQgjtPgshlGrBvAq1MPqTt9XC3BBui9XChcXDAMNczKkGjcWqgcr9qmoA8hVmLqXwyH6DPnEKsc5FJUEZDixpxSpjhRkIg0kj1EdwUT3oWA41HHREqAwKNRwVDFKOGZshqoNWOlEpB2Vj6p2oaoEL9VD2aLTAyOlDSykUTZO+nDZTiDnD8TbVwoUpkIcDhkNUw66Wi3qftl/DlBGpnwuSDBBHeQuAnCv8BrLDSmsqoXBYiXIAitYHxyRdnREHYomSI6oHaZqkUIJB/YQ0NVAgqxYmTl8eCQlFCqHv2cFSyrETUHRjLlMLbXmwgJiAwjZDgXyYbpqca4WoDcfRn/rhqAXgIYHh2FiiGibAUxiRVSsF+QAe1Bls2op5RzUc0tOyc0rBLOmEphLqIyR/wQAipQ5IaUQLEHKISbWgQTUY2MDAeA3lXY9ICmIMCkadSuRpmT4UUEh+wthX0FaK2msYGY5TvRxbLRHHxoWpBaCDIcYSE9JurnCIC/mKKsbipBGZd5BSirwsKQLFH/8cHGiID4NJl2WpgFE1RLMzGo1ZPTBTpRI4QUBTB9sq0QIDgDYdjDpogcGOxdgehq1KFywgQuzRWC6P04dJKOzyFeZSCBtzLRH3TC0ADw0Me6QTcy0UKVQB6A8sKYh2ShHHWTDb+QAMzqgG+fEMbhYOMTsISPclSI9GB2l+1B6Ooh6sUkgKQiHgIP0UBBKpQ9PhYLDz9q7GFgxqWNTzRXOk6QK9GAraj8GmEktTiLp50syfrN/CBaoF4KGBYS6WjtOwb0qhaUM9ZoP1G4DSjBRgxBsVpuFAsstICjETAsdaPHDlJVSAkAFhMhBUKUg5YFILotxk2Tx3cZIf8zZWDwUULDAmgFB3WLItDrDzxTqBgqqB1LnJKocGFPZMIdrn4P6oBeAhguFY1bBgv0VKYT8jlb/pN4QMADgHeOmVwFQqB6aoWgZVIxrRd9BnYXKQFGHglF5QsIqBjZdgICGASKAAIix2nLIpA3IMCK7UAxewUCCMVAKPoZBbGzCtFBQKplViia+Q/2YLDMd7GA8PDHNxrGrYJ6UAzI/OTcJhlFYkE1D6PHCs+DTkW5/zjVtIN0HGJkpKyoRNs2QNiZRGABkWyMvlOcuzFg4ZCIxaOYwUAxsgJBWhHZQaqQOP+ynMQsEqBfkbTUJBv0KdQtj1rd9Nmt1DLVxoGgE8VDDMqYalRuQ+KQUfCId0PzVlxUCUOkERB3BqmYi7wIA85KR0ahJPMwEiKYfAxkvISgJAw2OYlww2jYjLaCiGrA5Kb6EEAmwKkSq9bOOziThSDFNQKABRgaCunFMpxALD8T7FwwTDMbE0pag7Pu2Cg95PYeEg83oPZVYMIaYYQwQGAoOHrB5ULcid2SUgBApkVYIjsIz7kJUCVYbjdDpR3InNZpm5AYioDpKasAoiVGmDBYWCoFIHeV2u/LugMB5kJacQbEFQQWFXCnFf1ALwkMFwqGqwMZdSjPwGMp8BRnDwXrpNI8OBKbdWSK1UxQDHERQhNl8m9SAVEMQxvSDKgKDY10EBQGJCUp1KAKWvYL56Cw7TYDCpRCiXrd8wCQQ26YNVCQqH2juwTZK1p7DAbMx/1xlfof6dmN/I4rhwKAAPGQzAPBzqTfdNKYzf0DQjoxkwhoOT3kayGfmoJngQz0FbCNSUFKeQB8rGZJqiAEQekJrlgbiV0VinD8rGAgzj81U83k1TCQsCXc+VOrAqQoCQYKBpAyOnC6nCm9TBNEM2myT3gMKUr1DE0hTiylOMhw2GudiZMozfn/IbRnAITipuAw7phyktDxLkg9zoJIBQ34GQ1QPpFdn0uTCAAMmzMgsocLrlGsigAEFu9zbfjwg0uo1KPld5DKXXYJSBgUGRTqSKbIBglcFo3qQIO4zGWSiYv90ICg8whdDoYDhhSjG578mWihk4uKwQIECggGxKmtQCTCmlSPMOJSB0TIVA0WtwnFQE9PkWCgoAMLCQA01Cofi+MKmEggBowiB7EA0g2LQhwaNSA63ejPtCYYfZ2ITCoSnEFUUHw55xUEphzUgd+HUpHBDfggCBRPfb1AKOypSCKkCEuI4HyqpCx4AAspIwHZk4oOrUJHJ7gccQ12UFkeZbMGCbVkwAYUolWAhMmYxW+s9BYanZeEwKcSVqAehgiLGHaoirTgwHYLq1wsLBFCOlFtYkcBEc7MScVEBousECCEJWEUBWEhYU4HQ86yvMOTKF16D1g61qmIZBAYDmcq7we6sEPfYhULBRVfr7mEJodDBo7AmHyfcPgUO6DwNoGpIk3oIBQKEeKkBkRUBpTMfWcoIEMAYF5DMAaKap0kYBAGCsHmoYyNfdCYQplbA0ddC/yyFQWOor3LPoYFgau/yGc8ABLCYj5tVDAABuK4haNSR/gjMkpBzaIauARTrIbjJQo0IlEACp4qdtDQzG6/YHQjzEDBRs64Oe06VQ2OUr3CO1AHQwlDGnGlqbz8Eh7XIeDgByawWAohOULI9aLBrqAZQHYEnHaABCgQAnxmVAUhKQ9CF6C5QrxhLjUc9fPW8rva6fg4HdZgoIxX52+Am6vAAKRTxgKAAdDOM4xm+wYVoq5uBQNmWK65fgANjUAvV+AHkY7ji9aCoIoA0JsFEOclhzDnZ1h7ZBLTjUaYOuK67oXGw/AkK93ZRK0H1XqUPert0kmd4328eVR5iNVxwdDPvGAWYksAccgLYp6QHQhPcAjAABis+5LDwIYAwJwDR/soEAJzglLEwCs7oqmrpCNRzqSq7rFAZmeRIIsk1TJaTtJ/yEogzL04e4WH3PndC4TrUAdDC0Y1dKcU44WN8BaKuH2nsApgHBbFQExpAA2qCQwxXvH5pO6HnQdRUkRo+Ia6UM+l3ZVvSGSgCmUwdbpmOhsCuuGApAB8N03AYcgLKHJFD5Dia1AJreA6b2ZwFhvssIEsAYFHadRitdsjG6mk6nFIUy0Gkt4xtAiKuXqYS0rX7eHu8UULiHvoKNDoa5ODUcgLK1AlieWgBj9WDSiwSIonmTTerAbUgApZ8w1RLR8B7SOWqem7y+CQI7bb1fVeZZIOg6WZ4Egll3Nijck1gMBiIaAHwUwIvM/F1E9JUA3gPgNQA+BuD7mfmGiB4DeDeAPwvgjwB8LzN/6uQlv63YBYfWR6bgABRNmQCmUwssUQ/ACBCoPAgg7psoqwgLiViINE3Pz7TrD4mplGIOBsDYQyi2nUgbzDa7VEKxjd233VdaPAAK90AtAEVr+M746wA+YZZ/BMCPMvNXA/gcgLfL+rcD+Jys/1HZ7rpj7o898UPh+gdntzPvNX/ILckb2LTPB7OsrxBhEBjs4whFnAYv8fkVQnx5eQU28+alV+1TvNgcQ1+2ZUHL5X0EQgjt76z7aZwHTmZkWN7y0KEwGYvAQETPAPjvAfyfskwAvhXAT8sm7wLwF2T+LbIMef/baOqBC/cllsCh3m4KDq0ftVSUxYBoVRh9VZWwWXktLOrK3Hq1tq33UYNgAgacPuvle/hZIIzOn567Blwn75LsUBjF0lTiHwL4WwC+VJZfA+DzzLyV5RcAvE7mXwfg0wDAzFsi+oJs/4d2h0T0LIBnAeAJXnlg8W8xDvAb4uodPSSB+dQiriy8BwBt/wHIqGdJJTTN0PRBvkvyI3T/Gva4Gvq+X/Djb1UQ24HIvD/bb2AqjTDrRkAoPrd/6hBXdSgAC8BARN8F4LPM/DEietOpDszMzwF4DgBeRU9dx5ldAgdgdyeoCd8hHqLRylD/2JcAAih9CCBBAkAbFEAbFodEVVmaw6kBZaVrVeDKQyj2tQ8Qqn0sbo58gFAAlimGbwHw54nozQCeAHgVgB8D8GoiWolqeAbAi7L9iwBeD+AFIloB+DJEE/J+xBIzckkPyRoiFRwAtAFRrZsEBGAgYSFgTMkaFEABC42lmeDcg1vKDRfCoPrsLBCq9bM3QnUo7IydHgMz/xAzP8PMbwDwVgAfZua/BOAjAL5bNnsbgPfJ/PtlGfL+h3nyF3OlseTrHCJTK0OMWz/6On+uc+hgXsm0C9V68wq+3E4MTPtiHxa96s8lL6Eohy+9iVZ57bF5xlicOw/2nNpz3aGwKI7px/CDAN5DRH8fwK8AeKesfyeAf0JEzwP4j4gwuX9xhHIAsFdqAUyoh/hGeaV0eT9kf9tNJaHv1eU+Mp04RDlU7zWhWO97adpQHyutOsBPqMtwT2MvMDDzzwP4eZn/XQDf0NjmJQB/8QRlu/w4EA5x9YLUAlgOiPhmM80AZiABFClFVcqiDItirutwXemWwiC+OfnePmlDXHWgSqjLcY+j93w8No6EA9BQD3FlnC4BBDCrImYhkbaZqRST4Ci+zPz7jco4vsrPwKDx/slUwsS2420eBhSADobTxFI4AMvUg25fpxdAGxDAMhWhu3bjMjRhUYSfVw4LbjJqWk3HwqB17H2AMLH9eJuHAwWgg+F0Ya/Ws9sdoR6A5YAApvsk1JWxUhStSHd9TsQif7k1IEr88M5tDwVCXH2ESogHX7bdPYoOhlPHudRDvf0EIIAZSGj5bLRAUccCcORyHXj1bXxuEQyA/YEw85lGIZZtd8+ig+EcsQQOwH7qQbePb+R19se/FBLANCjyB80xFlaioqw7KtTEPhf3hQA6EM4YHQznin3gABwPCGCkImIxGpAA2hXTeg+nrBg7wLIXDIDDgDDzuUaBlm13j6OD4Zyx1HcAJtVDfGsHIOKbeb6hImJxxj/4nbA4cexMSQ642p8MCECHgkQHw23ECdRDfHsCEPaz9efrSlN9dq6iHnNT7HJP4vBK3YFwvuhguK3YVz0AOwERN9kDEkC7Ik40Q56lJ/uCZs1dFfqkQAA6FBrRwXDbsVQ9ADsBETeZURF2H3P72VXRlvZ8XFLpW7GgIi8ajLUD4WTRwXAXsY96APYCRNxsASTyxruPf2iFX1qGyU0XHveQMRg7FGajg+EuYx/1ACwCRNxsASTqfbZiCTT23efOj+5RYTsQzhYdDHcd+6oHYFl6kDYtK8JOUEwd50xx0MNhOxDOHh0MlxKHAALYCxJx83YF2QsYB8ZRT4g+BlIdCntHB8OlxaGAAPaGRPnRC6w8xyqWDoSDo4PhUuMYQABHQeLO4hSpS4fBSaKD4dLjWEAAh7dGnDtO6WF0IJw0OhiuJeoxFo7e30SlPDUwzm1gdiCcJToYrjFOoSIm933+loijo8Pg7NHBcM1xahVxydFhcKvRwXBf4j5CosPgzqKD4T5Ga5Sma4gOgouJDoaHEK0Kd9ew6BC46OhgeKgxVzFPBY1e+a82Ohh6jKNX6AcfF9DLpUePHpcWHQw9evQYRQdDjx49RtHB0KNHj1F0MPTo0WMUHQw9evQYRQdDjx49RtHB0KNHj1F0MPTo0WMUi8BARJ8iot8gol8loo/KuqeI6INE9Nsy/ZOynojoHxHR80T060T0def8Aj169Dh97KMY/ltm/hpm/npZfgeADzHzGwF8SJYB4DsBvFFezwL48VMVtkePHrcTx6QSbwHwLpl/F4C/YNa/m2P8AoBXE9HTRxynR48etxxLwcAA/h8i+hgRPSvrXsvMn5H53wfwWpl/HYBPm8++IOuKIKJnieijRPTRDV4+oOg9evQ4Vyy9u/LPMfOLRPSnAHyQiP4/+yYzMxHtdUseMz8H4DkAeBU91W/n69HjgmKRYmDmF2X6WQA/A+AbAPyBpggy/axs/iKA15uPPyPrevTocSWxEwxE9CeI6Et1HsB/B+DjAN4P4G2y2dsAvE/m3w/gL0vrxDcB+IJJOXr06HEFsSSVeC2An6E4qs8KwD9j5n9NRL8E4L1E9HYAvwfge2T7DwB4M4DnAXwRwA+cvNQ9evQ4axBfwGg9RPTHAD551+VYGF8O4A/vuhAL4lrKCVxPWa+lnEC7rP8VM3/Fkg9fytBunzT9Iy46iOij11DWaykncD1lvZZyAseXtXeJ7tGjxyg6GHr06DGKSwHDc3ddgD3iWsp6LeUErqes11JO4MiyXoT52KNHj8uKS1EMPXr0uKC4czAQ0XcQ0SflNu137P7EWcvyk0T0WSL6uFl3kbeXE9HriegjRPRbRPSbRPTXL7G8RPSEiP49Ef2alPPvyfqvJKJflPL8FBE9kvWPZfl5ef8Nt1FOU96BiH6FiH72wst53qEQmPnOXgAGAL8D4KsAPALwawD+zB2W578B8HUAPm7W/W8A3iHz7wDwIzL/ZgD/CgAB+CYAv3jLZX0awNfJ/JcC+A8A/syllVeO9yUyvwbwi3L89wJ4q6z/CQD/o8z/TwB+QubfCuCnbvm8/k0A/wzAz8rypZbzUwC+vFp3sr/9rX2RiS/3zQB+ziz/EIAfuuMyvaECwycBPC3zTyP2uQCA/wPA97W2u6Nyvw/At19yeQG8EsAvA/hGxM43q/p3AODnAHyzzK9kO7ql8j2DOLbItwL4WalIF1dOOWYLDCf72991KrHoFu07jqNuL7+NEBn7tYhX44srr8jzX0W80e6DiCrx88y8bZQllVPe/wKA19xGOQH8QwB/C0CQ5ddcaDmBMwyFYONSej5eRTDvf3v5uYOIvgTAvwDwN5j5P5F5UvWllJeZPYCvIaJXI96d+6fvtkTjIKLvAvBZZv4YEb3pjouzJE4+FIKNu1YM13CL9sXeXk5Ea0Qo/FNm/pey+mLLy8yfB/ARREn+aiLSC5MtSyqnvP9lAP7oFor3LQD+PBF9CsB7ENOJH7vAcgI4/1AIdw2GXwLwRnF+HyGaOO+/4zLVcZG3l1OUBu8E8Alm/geXWl4i+gpRCiCiVyD6IJ9ABMR3T5RTy//dAD7MkhifM5j5h5j5GWZ+A+Lv8MPM/JcurZzALQ2FcFtmyYyJ8mZER/13APydOy7LPwfwGQAbxDzs7Yh544cA/DaAfwPgKdmWAPxjKfdvAPj6Wy7rn0PMM38dwK/K682XVl4A/zWAX5FyfhzA/yLrvwrAv0e8Pf//BvBY1j+R5efl/a+6g9/Bm5BbJS6unFKmX5PXb2q9OeXfvvd87NGjxyjuOpXo0aPHBUYHQ48ePUbRwdCjR49RdDD06NFjFB0MPXr0GEUHQ48ePUbRwdCjR49RdDD06NFjFP8/p9gd0dBePrEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(_get_gaussian((512,512)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def energy_score(x, T=1, dim=1):\n",
    "    'Return the energy score as proposed by  Liu, Weitang, et al. (2020).'\n",
    "    return -(T*torch.logsumexp(x/T, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsemblePredict():\n",
    "    'Class for prediction with multiple models'\n",
    "    def __init__(self, models_paths, zarr_store=None):\n",
    "        self.models_paths = models_paths\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.init_models()\n",
    "        \n",
    "        # Init zarr storage\n",
    "        self.store = str(zarr_store) if zarr_store else zarr.storage.TempStore()\n",
    "        self.root = zarr.group(store=self.store)\n",
    "        self.g_smx = self.root.require_group('smx')\n",
    "        self.g_std = self.root.require_group('std')\n",
    "        self.g_eng = self.root.require_group('energy')\n",
    "        \n",
    "    def init_models(self):\n",
    "        self.models = []\n",
    "        self.stats = None\n",
    "        for p in self.models_paths:        \n",
    "            model, stats = load_smp_model(p)\n",
    "            if not self.stats: self.stats = stats\n",
    "            assert np.array_equal(stats, self.stats), 'Only models trained on the same stats are allowed.'\n",
    "            model.float()\n",
    "            model.eval()\n",
    "            model.to(self.device)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, \n",
    "                ds, \n",
    "                use_tta=True, \n",
    "                bs=4, \n",
    "                use_gaussian=True, \n",
    "                sigma_scale=1./8, \n",
    "                uncertainty_estimates=True, \n",
    "                energy_T = 1., \n",
    "                verbose=0):\n",
    "        \n",
    "        if verbose>0: print('Ensemble prediction with models:', self.models_paths)\n",
    "            \n",
    "        tfms = [tta.HorizontalFlip(),tta.VerticalFlip()] if use_tta else []\n",
    "        if verbose>0: print('Using Test-Time Augmentation with:', tfms)\n",
    "                      \n",
    "        dl = DataLoader(ds, bs, num_workers=0, shuffle=False, pin_memory=True)\n",
    "\n",
    "        # Create zero arrays\n",
    "        data_shape = ds.image_shapes[0]\n",
    "        softmax = np.zeros((*data_shape, ds.c), dtype='float32')\n",
    "        merge_map = np.zeros(data_shape, dtype='float32')\n",
    "        stdeviation = np.zeros(data_shape, dtype='float32') if uncertainty_estimates else None\n",
    "        energy = np.zeros(data_shape, dtype='float32') if uncertainty_estimates else None\n",
    "\n",
    "        # Define merge weights\n",
    "        if use_gaussian:\n",
    "            mw_numpy = _get_gaussian(ds.output_shape, sigma_scale)\n",
    "        else: \n",
    "            mw_numpy = np.ones(dl.output_shape)\n",
    "        mw = torch.from_numpy(mw_numpy).to(self.device)\n",
    "        \n",
    "        # Loop over tiles (indices required!)\n",
    "        for tiles, idxs in iter(dl):\n",
    "            tiles = tiles.to(self.device)\n",
    "            smx_merger = tta.Merger()\n",
    "            if uncertainty_estimates: \n",
    "                energy_merger = tta.Merger()\n",
    "            \n",
    "            # Loop over tt-augmentations\n",
    "            for t in tta.Compose(tfms): \n",
    "                aug_tiles = t.augment_image(tiles)\n",
    "                model_merger = tta.Merger()\n",
    "                if uncertainty_estimates: engergy_list = []\n",
    "                \n",
    "                # Loop over models\n",
    "                for model in self.models:\n",
    "                    with torch.no_grad(): \n",
    "                        logits = model(aug_tiles)\n",
    "                    logits = t.deaugment_mask(logits)\n",
    "                    smx_merger.append(F.softmax(logits, dim=1)) \n",
    "                    if uncertainty_estimates: \n",
    "                        energy_merger.append(-energy_score(logits, energy_T)) #negative energy score\n",
    "\n",
    "            out_list = []\n",
    "            # Apply gaussian weigthing\n",
    "            batch_smx = smx_merger.result()*mw.view(1,1,*mw.shape)\n",
    "            # Reshape and append to list\n",
    "            out_list.append([x for x in batch_smx.permute(0,2,3,1).cpu().numpy()])\n",
    "            \n",
    "            if uncertainty_estimates:\n",
    "                batch_std = torch.mean(smx_merger.result('std'), dim=1)*mw.view(1,*mw.shape)\n",
    "                out_list.append([x for x in batch_std.cpu().numpy()])\n",
    "\n",
    "                batch_energy =  energy_merger.result()*mw.view(1,*mw.shape)\n",
    "                out_list.append([x for x in batch_energy.cpu().numpy()])\n",
    "\n",
    "            # Compose predictions\n",
    "            for preds in zip(*out_list, idxs):\n",
    "                if uncertainty_estimates: smx,std,eng,idx = preds \n",
    "                else: smx, idx = preds\n",
    "                out_slice = ds.out_slices[idx]\n",
    "                in_slice = ds.in_slices[idx]\n",
    "                softmax[out_slice] += smx[in_slice]\n",
    "                merge_map[out_slice] += mw_numpy[in_slice]\n",
    "                \n",
    "                if uncertainty_estimates:\n",
    "                    stdeviation[out_slice] += std[in_slice]\n",
    "                    energy[out_slice] += eng[in_slice]\n",
    "                    \n",
    "        # Normalize weighting           \n",
    "        softmax /= merge_map[..., np.newaxis]\n",
    "        if uncertainty_estimates:\n",
    "            energy /= merge_map\n",
    "            stdeviation /= merge_map   \n",
    "            \n",
    "        return softmax, stdeviation, energy\n",
    "    \n",
    "    def predict_images(self, image_list, ds_kwargs={}, verbose=1, **kwargs):\n",
    "        \"Predict images in 'image_list' with kwargs and save to zarr\"\n",
    "        for f in progress_bar(image_list, leave=False):\n",
    "            if verbose>0: print(f'Predicting {f.name}')\n",
    "            ds = TileDataset([f], stats=self.stats, return_index=True, **ds_kwargs)\n",
    "            softmax, stdeviation, energy = self.predict(ds, **kwargs)\n",
    "            \n",
    "            # Save to zarr\n",
    "            self.g_smx[f.name] = softmax\n",
    "            if stdeviation is not None: self.g_std[f.name] = stdeviation\n",
    "            if energy is not None: self.g_eng[f.name] = energy\n",
    "        \n",
    "        return self.g_smx, self.g_std, self.g_eng       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleLearner(GetAttr):\n",
    "    _default = 'config' \n",
    "    def __init__(self, image_dir='images', mask_dir=None, config=None, path=None, ensemble_dir=None, item_tfms=None,\n",
    "                 label_fn=None, metrics=None, cbs=None, ds_kwargs={}, dl_kwargs={}, model_kwargs={}, stats=None, files=None):\n",
    "\n",
    "        self.config = config or Config()\n",
    "        self.stats = stats \n",
    "        self.dl_kwargs = dl_kwargs\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.add_ds_kwargs = ds_kwargs\n",
    "        self.item_tfms = item_tfms\n",
    "        self.path = Path(path) if path is not None else Path('.')\n",
    "        self.metrics = metrics or [Iou(), Dice()]\n",
    "        self.loss_fn = self.get_loss()\n",
    "        self.cbs = cbs or [SaveModelCallback(monitor='iou')] #ShowGraphCallback\n",
    "        self.ensemble_dir = ensemble_dir or self.path/'ensemble'    \n",
    "        \n",
    "        self.files = L(files) or get_image_files(self.path/image_dir, recurse=False)\n",
    "        assert len(self.files)>0, f'Found {len(self.files)} images in \"{image_dir}\". Please check your images and image folder'\n",
    "        if any([mask_dir, label_fn]):\n",
    "            if label_fn: self.label_fn = label_fn\n",
    "            else: self.label_fn = get_label_fn(self.files[0], self.path/mask_dir)\n",
    "            #Check if corresponding masks exist\n",
    "            mask_check = [self.label_fn(x).exists() for x in self.files]\n",
    "            chk_str = f'Found {len(self.files)} images in \"{image_dir}\" and {sum(mask_check)} masks in \"{mask_dir}\".'\n",
    "            assert len(self.files)==sum(mask_check) and len(self.files)>0, f'Please check your images and masks (and folders). {chk_str}'\n",
    "            print(chk_str)\n",
    "                  \n",
    "        else:\n",
    "            self.label_fn = label_fn\n",
    "        self.n_splits=min(len(self.files), self.max_splits)\n",
    "          \n",
    "        self.models = {}\n",
    "        self.recorder = {}\n",
    "        self._set_splits()\n",
    "        self.ds = RandomTileDataset(self.files, label_fn=self.label_fn, stats=self.stats, verbose=0)\n",
    "        self.stats = stats or self.ds.stats\n",
    "        self.in_channels = self.ds.get_data(max_n=1)[0].shape[-1]\n",
    "        self.df_val, self.df_ens, self.df_model, self.ood = None,None,None,None\n",
    "               \n",
    "    def _set_splits(self):\n",
    "        if self.n_splits>1:\n",
    "            kf = KFold(self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "            self.splits = {key:(self.files[idx[0]], self.files[idx[1]]) for key, idx in zip(range(1,self.n_splits+1), kf.split(self.files))}    \n",
    "        else:\n",
    "            self.splits = {1: (self.files[0], self.files[0])}\n",
    "            \n",
    "    def _compose_albumentations(self, **kwargs):\n",
    "        return _compose_albumentations(**kwargs)\n",
    "        \n",
    "    @property        \n",
    "    def pred_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['n_classes']= self.c\n",
    "        ds_kwargs['shift']= self.shift\n",
    "        ds_kwargs['border_padding_factor']= self.border_padding_factor\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property        \n",
    "    def train_ds_kwargs(self):\n",
    "        # Setting default shapes and padding\n",
    "        ds_kwargs = self.add_ds_kwargs.copy()\n",
    "        # Settings from config\n",
    "        ds_kwargs['stats']= self.stats\n",
    "        ds_kwargs['tile_shape']= (self.tile_shape,)*2\n",
    "        ds_kwargs['n_classes']= self.c\n",
    "        ds_kwargs['shift']= 1.\n",
    "        ds_kwargs['border_padding_factor']= 0.\n",
    "        ds_kwargs['flip'] = self.flip\n",
    "        ds_kwargs['albumentation_tfms'] = self._compose_albumentations(**self.albumentation_kwargs)\n",
    "        ds_kwargs['sample_mult'] = self.sample_mult if self.sample_mult>0 else None\n",
    "        return ds_kwargs\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        return f'{self.arch}_{self.encoder_name}_{self.c}classes'  \n",
    "                    \n",
    "    def get_loss(self):\n",
    "        kwargs = {'mode':self.mode,\n",
    "                  'classes':[x for x in range(1, self.c)],\n",
    "                  'smooth_factor': self.loss_smooth_factor,\n",
    "                  'alpha':self.loss_alpha, \n",
    "                  'beta':self.loss_beta, \n",
    "                  'gamma':self.loss_gamma}\n",
    "        return get_loss(self.loss, **kwargs)\n",
    "    \n",
    "    \n",
    "    def _get_dls(self, files, files_val=None):\n",
    "        ds = []\n",
    "        ds.append(RandomTileDataset(files, label_fn=self.label_fn, **self.train_ds_kwargs))\n",
    "        if files_val: \n",
    "            ds.append(TileDataset(files_val, label_fn=self.label_fn, **self.train_ds_kwargs))\n",
    "        else:\n",
    "            ds.append(ds[0])\n",
    "        dls = DataLoaders.from_dsets(*ds, bs=self.bs, pin_memory=True, **self.dl_kwargs)\n",
    "        if torch.cuda.is_available(): dls.cuda()\n",
    "        return dls\n",
    "    \n",
    "    def _create_model(self):\n",
    "        model = create_smp_model(arch=self.arch, \n",
    "                                 encoder_name=self.encoder_name, \n",
    "                                 encoder_weights=self.encoder_weights, \n",
    "                                 in_channels=self.in_channels, \n",
    "                                 classes=self.c, \n",
    "                                 **self.model_kwargs)\n",
    "        if torch.cuda.is_available(): model.cuda()\n",
    "        return model\n",
    "               \n",
    "    def fit(self, i, n_iter=None, base_lr=None, **kwargs):\n",
    "        n_iter = n_iter or self.n_iter\n",
    "        base_lr = base_lr or self.base_lr\n",
    "        name = self.ensemble_dir/f'{self.model_name}-fold{i}.pth'\n",
    "        model = self._create_model()\n",
    "        files_train, files_val = self.splits[i]\n",
    "        dls = self._get_dls(files_train, files_val)    \n",
    "        self.learn = Learner(dls, model, metrics=self.metrics, wd=self.wd, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim], cbs=self.cbs)\n",
    "        self.learn.model_dir = self.ensemble_dir.parent/'.tmp'\n",
    "        if self.mpt: self.learn.to_fp16()\n",
    "        print(f'Starting training for {name.name}')\n",
    "        epochs = calc_iterations(n_iter=n_iter,ds_length=len(dls.train_ds), bs=self.bs)\n",
    "        #self.learn.fit_one_cycle(epochs, lr_max)\n",
    "        self.learn.fine_tune(epochs, base_lr=base_lr)\n",
    "\n",
    "        print(f'Saving model at {name}')\n",
    "        name.parent.mkdir(exist_ok=True, parents=True)\n",
    "        save_smp_model(self.learn.model, self.arch, name, stats=self.stats)\n",
    "        self.models[i]=name\n",
    "        self.recorder[i]=self.learn.recorder\n",
    "        \n",
    "    def fit_ensemble(self, n_iter, skip=False, **kwargs):\n",
    "        for i in range(1, self.n+1):\n",
    "            if skip and (i in self.models): continue\n",
    "            self.fit(i, n_iter,  **kwargs)\n",
    "       \n",
    "    def set_n(self, n):\n",
    "        for i in range(n, len(self.models)):\n",
    "            self.models.pop(i+1, None)            \n",
    "        self.n = n\n",
    "                                                       \n",
    "    def get_valid_results(self, model_no=None, export_dir=None, filetype='.png', **kwargs):\n",
    "        res_list = []\n",
    "        model_list = self.models if not model_no else [model_no]\n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for i, model_path in model_list.items():\n",
    "            ep = EnsemblePredict(models_paths=[model_path])\n",
    "            _, files_val = self.splits[i]\n",
    "            g_smx, g_std, g_eng = ep.predict_images(files_val, bs=self.bs, ds_kwargs=self.pred_ds_kwargs, **kwargs)\n",
    "            \n",
    "            chunk_store = g_smx.chunk_store.path\n",
    "            for j, f in enumerate(files_val):\n",
    "                msk = self.ds.get_data(f, mask=True)[0]\n",
    "                pred = np.argmax(g_smx[f.name][:], axis=-1).astype('uint8')\n",
    "                m_iou = iou(msk, pred)\n",
    "                m_path = self.models[i].name\n",
    "                df_tmp = pd.Series({'file' : f.name,\n",
    "                        'model' :  m_path,\n",
    "                        'model_no' : i,\n",
    "                        'iou': m_iou,\n",
    "                        'dice': 2*m_iou/(m_iou+1),\n",
    "                        'mean_energy': np.mean(g_eng[f.name][:][pred>0]),\n",
    "                        'mean_uncertainty': np.mean(g_std[f.name][:][pred>0]),\n",
    "                        'image_path': f,\n",
    "                        'mask_path': self.label_fn(f),\n",
    "                        'softmax_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                        'engergy_path': f'{chunk_store}/{g_eng.path}/{f.name}' if g_eng is not None else None,\n",
    "                        'uncertainty_path': f'{chunk_store}/{g_std.path}/{f.name}'} if g_std is not None else None)\n",
    "                res_list.append(df_tmp)\n",
    "                if export_dir:   \n",
    "                    save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.model}_mask', filetype)\n",
    "                    if g_std is not None:\n",
    "                        save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_uncertainty', filetype)\n",
    "                    if g_eng is not None:\n",
    "                        save_unc(g_eng[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.model}_energy', filetype)\n",
    "        self.df_val = pd.DataFrame(res_list)\n",
    "        if export_dir: \n",
    "            self.df_val.to_csv(export_dir/f'val_results.csv', index=False)\n",
    "            self.df_val.to_excel(export_dir/f'val_results.xlsx')\n",
    "        return self.df_val\n",
    "        \n",
    "    def show_valid_results(self, model_no=None, files=None, **kwargs):\n",
    "        if self.df_val is None: self.get_valid_results(**kwargs)\n",
    "        df = self.df_val\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        if model_no is not None: df = df[df.model_no==model_no] \n",
    "        for _, r in df.iterrows():\n",
    "            img = self.ds.get_data(r.image_path)[0][:]\n",
    "            msk = self.ds.get_data(r.image_path, mask=True)[0]\n",
    "            pred = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            std = zarr.load(r.uncertainty_path)\n",
    "            _d_model = f'Model {r.model_no}'\n",
    "            if self.tta: plot_results(img, msk, pred, std, df=r, model=_d_model)  \n",
    "            else: plot_results(img, msk, pred, np.zeros_like(pred), df=r, model=_d_model)  \n",
    "          \n",
    "    def load_ensemble(self, path=None):\n",
    "        path = path or self.ensemble_dir\n",
    "        models = sorted(get_files(path, extensions='.pth', recurse=False))\n",
    "        assert len(models)>0, f'No models found in {path}'\n",
    "        self.models = {}\n",
    "        for i, m in enumerate(models,1):\n",
    "            self.models[i] = m\n",
    "        print(f'Found {len(self.models)} models in folder {path}')\n",
    "        print(self.models)\n",
    "                           \n",
    "    def get_ensemble_results(self, files, zarr_store=None, export_dir=None, filetype='.png', **kwargs):   \n",
    "        ep = EnsemblePredict(models_paths=self.models.values(), zarr_store=zarr_store)\n",
    "        g_smx, g_std, g_eng = ep.predict_images(files, bs=self.bs, ds_kwargs=self.pred_ds_kwargs, **kwargs)\n",
    "        chunk_store = g_smx.chunk_store.path\n",
    "        \n",
    "        if export_dir: \n",
    "            export_dir = Path(export_dir)\n",
    "            pred_path = export_dir/'masks'\n",
    "            pred_path.mkdir(parents=True, exist_ok=True)\n",
    "            unc_path = export_dir/'uncertainties'\n",
    "            unc_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        res_list = []\n",
    "        for f in files:\n",
    "            pred = np.argmax(g_smx[f.name][:], axis=-1).astype('uint8')\n",
    "            df_tmp = pd.Series({'file' : f.name,\n",
    "                                'ensemble' :  self.model_name,\n",
    "                                'n_models' : len(self.models),\n",
    "                                'mean_energy': np.mean(g_eng[f.name][:][pred>0]),\n",
    "                                'mean_uncertainty': np.mean(g_std[f.name][:][pred>0]),\n",
    "                                'image_path': f,\n",
    "                                'softmax_path': f'{chunk_store}/{g_smx.path}/{f.name}',\n",
    "                                'uncertainty_path': f'{chunk_store}/{g_std.path}/{f.name}' if g_std is not None else None,\n",
    "                                'energy_path': f'{chunk_store}/{g_eng.path}/{f.name}'} if g_eng is not None else None)\n",
    "            res_list.append(df_tmp)\n",
    "            if export_dir:   \n",
    "                save_mask(pred, pred_path/f'{df_tmp.file}_{df_tmp.ensemble}_mask', filetype)\n",
    "                if g_std is not None:\n",
    "                    save_unc(g_std[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.ensemble}_unc', filetype)\n",
    "                if g_eng is not None:\n",
    "                        save_unc(g_eng[f.name][:], unc_path/f'{df_tmp.file}_{df_tmp.ensemble}_energy', filetype)\n",
    "                    \n",
    "        self.df_ens  = pd.DataFrame(res_list)\n",
    "        return g_smx, g_std, g_eng\n",
    "    \n",
    "    def score_ensemble_results(self, mask_dir=None, label_fn=None):\n",
    "        if not label_fn:\n",
    "            label_fn = get_label_fn(self.df_ens.image_path[0], self.path/mask_dir)\n",
    "        for idx, r in self.df_ens.iterrows():\n",
    "            msk_path = self.label_fn(r.image_path)\n",
    "            msk = _read_msk(msk_path)\n",
    "            self.df_ens.loc[idx, 'mask_path'] = msk_path\n",
    "            pred = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            self.df_ens.loc[idx, 'iou'] = iou(msk, pred)\n",
    "        return self.df_ens\n",
    "       \n",
    "    def show_ensemble_results(self, files=None, model_no=None, unc=True, unc_metric=None):\n",
    "        assert self.df_ens is not None, \"Please run `get_ensemble_results` first.\"\n",
    "        if model_no is None: df = self.df_ens\n",
    "        else: df = self.df_models[df_models.model_no==model_no]\n",
    "        if files is not None: df = df.set_index('file', drop=False).loc[files]\n",
    "        for _, r in df.iterrows():\n",
    "            imgs = []\n",
    "            imgs.append(_read_img(r.image_path)[:])\n",
    "            if 'iou' in r.index: \n",
    "                imgs.append(_read_msk(r.mask_path))\n",
    "                hastarget=True\n",
    "            else:\n",
    "                hastarget=False\n",
    "            imgs.append(np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8'))\n",
    "            if unc: imgs.append(zarr.load(r.uncertainty_path))\n",
    "            plot_results(*imgs, df=r, hastarget=hastarget, unc_metric=unc_metric) \n",
    "                \n",
    "    def lr_find(self, files=None, **kwargs):\n",
    "        files = files or self.files\n",
    "        dls = self._get_dls(files)\n",
    "        model = self._create_model()\n",
    "        learn = Learner(dls, model, metrics=self.metrics, wd=self.wd, loss_func=self.loss_fn, opt_func=_optim_dict[self.optim])\n",
    "        if self.mpt: learn.to_fp16()\n",
    "        sug_lrs = learn.lr_find(**kwargs)\n",
    "        return sug_lrs, learn.recorder  \n",
    "    \n",
    "    def export_imagej_rois(self, output_folder='ImageJ_ROIs', **kwargs):\n",
    "        assert self.df_ens is not None, \"Please run prediction first.\"\n",
    "        \n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True, parents=True)\n",
    "        for idx, r in progress_bar(self.df_ens.iterrows(), total=len(self.df_ens)):\n",
    "            mask = np.argmax(zarr.load(r.softmax_path), axis=-1).astype('uint8')\n",
    "            energy = zarr.load(r.energy_path)\n",
    "            export_roi_set(mask, energy, name=r.file, path=output_folder, **kwargs)\n",
    "           \n",
    "    def clear_tmp(self):\n",
    "        try: \n",
    "            shutil.rmtree('/tmp/*', ignore_errors=True)\n",
    "            shutil.rmtree(self.path/'.tmp')\n",
    "            print(f'Deleted temporary files from {self.path/\".tmp\"}')\n",
    "        except: print(f'No temporary files to delete at {self.path/\".tmp\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "add_docs(EnsembleLearner, \"Meta class to train and predict model ensembles with `n` models\",\n",
    "         #save_model= \"Save `model` to `file` along with `arch`, `stats`, and `c` classes\",\n",
    "         #load_model=\"Load `model` from `file` along with `arch`, `stats`, and `c` classes\",\n",
    "         fit=\"Fit model number `i`\",\n",
    "         fit_ensemble=\"Fit `i` models and `skip` existing\",\n",
    "         #predict=\"Predict `files` with model at `model_path`\",\n",
    "         get_valid_results=\"Validate models on validation data and save results\",\n",
    "         show_valid_results=\"Plot results of all or `file` validation images\",\n",
    "         #ensemble_results=\"Merge single model results\",\n",
    "         get_ensemble_results=\"Get models and ensemble results\", \n",
    "         score_ensemble_results=\"Compare ensemble results (Intersection over the Union) to given segmentation masks.\",\n",
    "         show_ensemble_results=\"Show result of ensemble or `model_no`\",\n",
    "         load_ensemble=\"Get models saved at `path`\",\n",
    "         #compose_albumentations=\"Helper function to compose albumentations augmentations\",\n",
    "         #get_dls=\"Create datasets and dataloaders from files\",\n",
    "         #get_model=\"Get model architecture\",\n",
    "         get_loss=\"Get loss function from loss name (config)\",\n",
    "         set_n=\"Change to `n` models per ensemble\",\n",
    "         lr_find=\"Wrapper for learning rate finder\",\n",
    "         #show_mask_weights='Plot fn for masks and weights',\n",
    "         #ood_train=\"Train SVM for OOD Detection\",\n",
    "         #ood_score=\"Get OOD score\",\n",
    "         #ood_save='Save OOD model to path',\n",
    "         #ood_load='Load OOD model from path',\n",
    "         export_imagej_rois='Export ImageJ ROI Sets to `ouput_folder`',\n",
    "         clear_tmp=\"Clear directory with temporary files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"EnsembleLearner\" class=\"doc_header\"><code>class</code> <code>EnsembleLearner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>EnsembleLearner</code>(**`image_dir`**=*`'images'`*, **`mask_dir`**=*`None`*, **`config`**=*`None`*, **`path`**=*`None`*, **`ensemble_dir`**=*`None`*, **`item_tfms`**=*`None`*, **`label_fn`**=*`None`*, **`metrics`**=*`None`*, **`cbs`**=*`None`*, **`ds_kwargs`**=*`{}`*, **`dl_kwargs`**=*`{}`*, **`model_kwargs`**=*`{}`*, **`stats`**=*`None`*, **`files`**=*`None`*) :: `GetAttr`\n",
       "\n",
       "Meta class to train and predict model ensembles with `n` models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EnsembleLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
