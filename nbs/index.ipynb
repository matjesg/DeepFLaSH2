{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Welcome to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "![deepflash2](https://raw.githubusercontent.com/matjesg/deepflash2/master/nbs/media/logo/logo_deepflash2_transp-02.png)\n",
    "\n",
    "Official repository of deepflash2 - a deep learning pipeline for segmentation of fluorescent labels in microscopy images.\n",
    "\n",
    "![CI](https://github.com/matjesg/deepflash2/workflows/CI/badge.svg) \n",
    "[![PyPI](https://img.shields.io/pypi/v/deepflash2?color=blue&label=pypi%20version)](https://pypi.org/project/deepflash2/#description) \n",
    "[![PyPI - Downloads](https://img.shields.io/pypi/dm/deepflash2)](https://pypistats.org/packages/deepflash2)\n",
    "[![Conda (channel only)](https://img.shields.io/conda/vn/matjesg/deepflash2?color=seagreen&label=conda%20version)](https://anaconda.org/matjesg/deepflash2) \n",
    "[![Build fastai images](https://github.com/matjesg/deepflash2/workflows/Build%20deepflash2%20images/badge.svg)](https://github.com/matjesg/deepflash2)\n",
    "[![GitHub stars](https://img.shields.io/github/stars/matjesg/deepflash2?style=social)](https://github.com/matjesg/deepflash2/)\n",
    "[![GitHub forks](https://img.shields.io/github/forks/matjesg/deepflash2?style=social)](https://github.com/matjesg/deepflash2/)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start in 30 seconds\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matjesg/deepflash2/blob/master/nbs/deepflash2.ipynb)\n",
    "\n",
    "![deepflash2 training getting started](https://raw.githubusercontent.com/matjesg/deepflash2/master/nbs/media/screen_captures/GUI_Train_start.gif)\n",
    "\n",
    "Examplary training workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why using deepflash2?\n",
    "\n",
    "__The best of two worlds:__\n",
    "Combining state of the art deep learning with a barrier free environment for life science researchers.\n",
    "\n",
    "- End-to-end process for life science researchers\n",
    "    - graphical user interface - no coding skills required\n",
    "    - free usage on _Google Colab_ at no costs\n",
    "    - easy deployment on own hardware\n",
    "- Rigorously evaluated deep learning models\n",
    "    - Model Library\n",
    "    - easy integration new (*pytorch*) models\n",
    "- Best practices model training\n",
    "    - leveraging the _fastai_ library\n",
    "    - mixed precision training\n",
    "    - learning rate finder and fit one cycle policy \n",
    "    - advanced augementation \n",
    "- Reliable prediction on new data\n",
    "    - leveraging Bayesian Uncertainties\n",
    "\n",
    "**Kaggle Gold Medal and Innovation Price Winner**\n",
    "\n",
    "*deepflash2* does not only work on fluorescent labels. The *deepflash2* API built the foundation for winning the [Innovation Award](https://hubmapconsortium.github.io/ccf/pages/kaggle.html) a Kaggle Gold Medal in the [HuBMAP - Hacking the Kidney](https://www.kaggle.com/c/hubmap-kidney-segmentation) challenge. \n",
    "Have a look at our [solution](https://www.kaggle.com/matjes/hubmap-deepflash2-judge-price)\n",
    "\n",
    "![Gold Medal](https://www.kaggle.com/static/images/medals/competitions/goldl@1x.png)\n",
    "\n",
    "\n",
    "## Citing\n",
    "\n",
    "We're working on a peer reviewed publication. Until than, the preliminary citation is:\n",
    "\n",
    "```\n",
    "@misc{griebel2021deepflash2,\n",
    "  author = {Matthias Griebel},\n",
    "  title = {DeepFLasH2 - a deep learning pipeline for segmentation of fluorescent labels in microscopy images},\n",
    "  year = {2021},\n",
    "  publisher = {GitHub},\n",
    "  journal = {GitHub repository},\n",
    "  howpublished = {\\url{https://github.com/matjesg/deepflash2}}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "tbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Installing\n",
    "\n",
    "You can use **deepflash2** by using [Google Colab](colab.research.google.com). You can run every page of the [documentation](matjesg.github.io/deepflash2/) as an interactive notebook - click \"Open in Colab\" at the top of any page to open it.\n",
    " - Be sure to change the Colab runtime to \"GPU\" to have it run fast!\n",
    " - Use Firefox or Google Chrome if you want to upload your images.\n",
    "\n",
    "You can install **deepflash2**  on your own machines with conda (highly recommended):\n",
    "\n",
    "```bash\n",
    "conda install -c fastai -c pytorch -c matjesg deepflash2 \n",
    "```\n",
    "To install with pip, use\n",
    "\n",
    "```bash\n",
    "pip install deepflash2\n",
    "```\n",
    "If you install with pip, you should install PyTorch first by following the PyTorch [installation instructions](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Using Docker\n",
    "\n",
    "Docker images for __deepflash2__ are built on top of [the latest pytorch image](https://hub.docker.com/r/pytorch/pytorch/) and [fastai](https://github.com/fastai/docker-containers) images. **You must install [Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) to enable gpu compatibility with these containers.**\n",
    "\n",
    "- CPU only\n",
    "\n",
    "> `docker run -p 8888:8888 matjesg/deepflash`\n",
    "\n",
    "- With GPU support ([Nvidia-Docker](https://github.com/NVIDIA/nvidia-docker) must be installed.)\n",
    "has an editable install of fastai and fastcore.\n",
    "\n",
    "> `docker run --gpus all -p 8888:8888 matjesg/deepflash`\n",
    "\n",
    "All docker containers are configured to start a jupyter server. **deepflash2** notebooks are available in the `deepflash2_notebooks` folder.\n",
    "\n",
    "For more information on how to run docker see [docker orientation and setup](https://docs.docker.com/get-started/) and [fastai docker](https://github.com/fastai/docker-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Model Library\n",
    "\n",
    "We provide a model library with pretrained model weights. Visit our [model library documentation](https://matjesg.github.io/deepflash2/model_library.html) for information on the datasets of the pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating segmentation masks with Fiji/ImageJ\n",
    "\n",
    "If you don't have labelled training data available, you can use this [instruction manual](https://github.com/matjesg/DeepFLaSH/raw/master/ImageJ/create_maps_howto.pdf) for creating segmentation maps.\n",
    "The ImagJ-Macro is available [here](https://raw.githubusercontent.com/matjesg/DeepFLaSH/master/ImageJ/Macro_create_maps.ijm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Acronym\n",
    "\n",
    "A Deep-learning pipeline for Fluorescent Label Segmentation that learns from Human experts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
