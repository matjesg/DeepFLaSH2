{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoelbert/deepflash2/blob/master/nbs/tutorial_train_and_pred_monuseg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFi-0H19iDbD"
      },
      "source": [
        "# deepflash2 - Train and Predict Tutorial on MoNuSeg\n",
        "This notebook is optmizied to be executed on Google Colab (https://colab.research.google.com). It demonstrates how to use deepflash2 to train and predict on datasets comparable to [MoNuSeg: Multi-organ Nucleus Segmentation Challenge](https://monuseg.grand-challenge.org/).\n",
        "\n",
        "\n",
        "*   Please read the instructions carefully.\n",
        "*   Press the the *play* butten to execute the cells. It will show up between \\[     \\] on the left side of the code cells. \n",
        "*   Run the cells consecutively.\n",
        "\n",
        "*References*:\n",
        "\n",
        "Griebel, M., Segebarth, D., Stein, N., Schukraft, N., Tovote, P., Blum, R., & Flath, C. M. (2021). Deep-learning in the bioimaging wild: Handling ambiguous data with deepflash2. arXiv preprint arXiv:2111.06693."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFBTANoYcvbV"
      },
      "source": [
        "## About the Example MoNuSeg Dataset\n",
        "from https://monuseg.grand-challenge.org: Training data containing 30 images and around 22,000 nuclear boundary annotations has been released to the public previously as a dataset article in IEEE Transactions on Medical imaging in 2017.\n",
        "\n",
        "* The train dataset (images and annotations) can be downloaded from https://drive.\n",
        "google.com/file/d/1ZgqFJomqQGNnsx7w7QBzQQMVA16lbVCA/view\n",
        "\n",
        "\n",
        "* Test set images with additional 7000 nuclear boundary annotations are available here MoNuSeg 2018 Testing data. Please cite the following papers if you use the training and testing datasets of this challenge: The test dataset can be downloaded from https://drive.google.com/file/d/1NKkSQ5T0ZNQ8aUhh0a8Dt2YKYCQXIViw/view\n",
        "\n",
        "How to download and preprocess the data can be found in the [corresponding Notebook](https://github.com/matjesg/deepflash2/blob/master/paper/challenge_data/preprocess_monuseg.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![MonNuSegCover.png](https://rumc-gcorg-p-public.s3.amazonaws.com/i/2020/02/22/Snip20200222_7.png)"
      ],
      "metadata": {
        "id": "_s2BsatTc3lR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8W1ppgOiDbE"
      },
      "source": [
        "## Setup\n",
        "In this section, you will set up the training environment, install all dependencies and connect to the drive with the prepared datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_9vpEvAiDbE"
      },
      "outputs": [],
      "source": [
        "# Install deepflash package and import necessary files\n",
        "!pip install deepflash2 --q\n",
        "import numpy as np\n",
        "from deepflash2.all import *\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SnksaRKiDbF"
      },
      "source": [
        "### Settings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzfG41MYiDbF"
      },
      "source": [
        "Prior to training and predicting directorys need to be specified and parameters need to be set. For convenience exissting Google Drive folders can be used. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3io5T24giDbF"
      },
      "outputs": [],
      "source": [
        "#################### Directories ####################\n",
        "\n",
        "# Connect to drive\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "except:\n",
        "  print('Google Drive is not available.')\n",
        "\n",
        "SEED = 0 # We used seeds [0,1,2] in our experiemnts\n",
        "OUTPUT_PATH = Path(\"/content/predictions\") # Save predictions here\n",
        "MODEL_PATH = Path(\"/content/models\") # Save models here\n",
        "TRAINED_MODEL_PATH= Path('/gdrive/MyDrive/deepflash2-paper/models/')\n",
        "DATA_PATH = Path('/gdrive/MyDrive/deepflash2-paper/data')\n",
        "\n",
        "#################### Parameters ####################\n",
        "DATASET = 'monuseg' \n",
        "mask_directory='masks_preprocessed'\n",
        "\n",
        "# Datasets have different numbers of classes - 2 in case of monuseg\n",
        "num_classes = 2\n",
        "# Diameters are calculated using the median sizes from the respective training sets - 21 in case of monuseg\n",
        "diameter = 21 \n",
        "\n",
        "# Create deepflash2 config class\n",
        "cfg = Config(random_state=SEED, \n",
        "            num_classes=num_classes, scale= 1.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oykNyZ40iDbO"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "- Initialize `EnsembleLearner`\n",
        "- Plot images and masks to show if they are correctly loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBpD9GYUiDbO"
      },
      "outputs": [],
      "source": [
        "train_data_path = DATA_PATH/DATASET/'train'\n",
        "ensemble_path = MODEL_PATH/DATASET/f'{SEED+1}' \n",
        "\n",
        "el = EnsembleLearner(image_dir='images', \n",
        "                     mask_dir=mask_directory, \n",
        "                     config=cfg, \n",
        "                     path=train_data_path, \n",
        "                     ensemble_path=ensemble_path)\n",
        "\n",
        "el.ds.show_data(max_n=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtKa78nLiDbO"
      },
      "source": [
        "## Train models\n",
        "\n",
        "- Train model ensemble with 5 models\n",
        "  - 2500 iterations for each model\n",
        "- You can skip this step use the trained models from our paper (see next section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4PzLyj8iDbO"
      },
      "outputs": [],
      "source": [
        "#el.fit_ensemble()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MElWzfbEiDbO"
      },
      "source": [
        "## Prediction on test set\n",
        "\n",
        "We save\n",
        "- Semantic segmentation masks (.png)\n",
        "- Instance segmentation masks (.tif) using the cellpose flow representations\n",
        "- Foreground uncertainty scores *U*\n",
        "\n",
        "To ensure reproducibilty we will use the trained models from our paper!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = DATA_PATH/DATASET/'test'\n",
        "ensemble_name = f'{DATASET}_ensemble_{SEED+1}.pt'\n",
        "ensemble_trained_dir = Path(\"/content/trained_models\")/DATASET\n",
        "ensemble_trained_dir.mkdir(exist_ok=True, parents=True)\n",
        "ensemble_trained_path = ensemble_trained_dir/ensemble_name\n",
        "prediction_path = OUTPUT_PATH/DATASET/f'{SEED+1}'\n",
        "\n",
        "#load the training data from the training data\n",
        "!wget -O {ensemble_trained_path.as_posix()} https://github.com/matjesg/deepflash2/releases/download/model_library/{ensemble_name}\n",
        "\n",
        "ep = EnsemblePredictor('images',\n",
        "                        path=test_data_path, \n",
        "                        config=cfg, \n",
        "                        ensemble_path=ensemble_trained_path) \n",
        "\n",
        "# Predict and save semantic segmentation masks\n",
        "ep.get_ensemble_results(ep.files, export_dir=prediction_path)\n",
        "\n",
        "# Save uncertainty scores\n",
        "ep.df_ens.to_csv(prediction_path/'uncertainty_scores.csv', index=False)\n",
        "\n",
        "# Show results scores\n",
        "ep.show_ensemble_results()"
      ],
      "metadata": {
        "id": "XW1lbojZ7rmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Predicting class {1}')\n",
        "ep.config.cellpose_export_class=1\n",
        "ep.config.cellpose_diameter=diameter\n",
        "ep.get_cellpose_results(export_dir=prediction_path)\n",
        "ep.show_cellpose_results()"
      ],
      "metadata": {
        "id": "8PLXAaNdOEof"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "tutorial_train_and_pred.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}