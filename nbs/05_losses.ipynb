{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp losses\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> Implements popular segmentation loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *\n",
    "from fastai.torch_core import TensorImage, TensorMask\n",
    "from fastai.losses import CrossEntropyLossFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import fastai\n",
    "from fastai.torch_core import TensorBase\n",
    "import segmentation_models_pytorch as smp\n",
    "from deepflash2.utils import import_package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses implemented here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "LOSSES = ['CrossEntropyLoss', 'DiceLoss', 'SoftCrossEntropyLoss', 'CrossEntropyDiceLoss',  'JaccardLoss', 'FocalLoss', 'LovaszLoss', 'TverskyLoss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Wrapper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper for handling different tensor types from [fastai](https://docs.fast.ai/torch_core.html#TensorBase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FastaiLoss(_Loss):\n",
    "    'Wrapper class around loss function for handling different tensor types.'\n",
    "    def __init__(self, loss, axis=1):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.axis=axis\n",
    "        \n",
    "    #def _contiguous(self, x): return TensorBase(x.contiguous())\n",
    "    def _contiguous(self,x):\n",
    "        return TensorBase(x.contiguous()) if isinstance(x,torch.Tensor) else x\n",
    "    \n",
    "    def forward(self, *input):\n",
    "        #input = map(self._contiguous, input)        \n",
    "        input = [self._contiguous(x) for x in input]\n",
    "        return self.loss(*input) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper for combining different losses, adapted from from [pytorch-toolbelt](https://github.com/BloodAxe/pytorch-toolbelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# from https://github.com/BloodAxe/pytorch-toolbelt/blob/develop/pytorch_toolbelt/losses/joint_loss.py\n",
    "class WeightedLoss(_Loss):\n",
    "    '''\n",
    "    Wrapper class around loss function that applies weighted with fixed factor.\n",
    "    This class helps to balance multiple losses if they have different scales\n",
    "    '''\n",
    "    def __init__(self, loss, weight=1.0):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.loss(*input) * self.weight\n",
    "\n",
    "class JointLoss(_Loss):\n",
    "    'Wrap two loss functions into one. This class computes a weighted sum of two losses.'\n",
    "\n",
    "    def __init__(self, first: nn.Module, second: nn.Module, first_weight=1.0, second_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.first = WeightedLoss(first, first_weight)\n",
    "        self.second = WeightedLoss(second, second_weight)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        return self.first(*input) + self.second(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "class DeepSupervisionLoss(nn.Module):\n",
    "    def __init__(self, criterion):\n",
    "        super().__init__()\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        loss = 0\n",
    "        div = 1\n",
    "        for i, input_head in enumerate(inputs):\n",
    "            #target = interpolate(targets, size=input_head.shape, mode='nearest')\n",
    "            targets_scaled = torch.nn.functional.adaptive_max_pool2d(targets.float(), input_head.shape[-2:]).long()\n",
    "            loss += self.criterion(input_head, targets_scaled)/div\n",
    "            div *= 2\n",
    "            if i>2: break\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular segmentation losses\n",
    "\n",
    "The `get_loss()` function loads popular segmentation losses from [Segmenation Models Pytorch](https://github.com/qubvel/segmentation_models.pytorch) and [kornia](https://kornia.readthedocs.io/en/latest/losses.html#semantic-segmentation): \n",
    "- (Soft) CrossEntropy Loss\n",
    "- Dice Loss\n",
    "- Jaccard Loss\n",
    "- Focal Loss\n",
    "- Lovasz Loss\n",
    "- TverskyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def get_loss(loss_name, mode='multiclass', deep_supervision=False, classes=[1], smooth_factor=0., alpha=0.5, beta=0.5, gamma=2.0, reduction='mean', **kwargs):\n",
    "    'Load losses from based on loss_name'\n",
    "    \n",
    "    assert loss_name in LOSSES, f'Select one of {LOSSES}'\n",
    "       \n",
    "    if loss_name==\"CrossEntropyLoss\": \n",
    "        loss = fastai.losses.CrossEntropyLossFlat(axis=1) \n",
    "        \n",
    "    if loss_name==\"SoftCrossEntropyLoss\":   \n",
    "        loss = smp.losses.SoftCrossEntropyLoss(smooth_factor=smooth_factor, **kwargs)\n",
    "\n",
    "    elif loss_name==\"DiceLoss\": \n",
    "        loss = smp.losses.DiceLoss(mode=mode, classes=classes, **kwargs)\n",
    "\n",
    "    elif loss_name==\"JaccardLoss\": \n",
    "        loss = smp.losses.JaccardLoss(mode=mode, classes=classes, **kwargs)\n",
    "\n",
    "    elif loss_name==\"FocalLoss\": \n",
    "        loss = smp.losses.FocalLoss(mode=mode, alpha=alpha, gamma=gamma, reduction=reduction, **kwargs)\n",
    "\n",
    "    elif loss_name==\"LovaszLoss\": \n",
    "        loss = smp.losses.LovaszLoss(mode=mode, **kwargs)\n",
    "\n",
    "    elif loss_name==\"TverskyLoss\": \n",
    "        kornia = import_package('kornia')\n",
    "        loss = kornia.losses.TverskyLoss(alpha=alpha, beta=beta, **kwargs)\n",
    "\n",
    "    elif loss_name==\"CrossEntropyDiceLoss\":\n",
    "        dc = smp.losses.DiceLoss(mode=mode, classes=classes, **kwargs)\n",
    "        ce = fastai.losses.CrossEntropyLossFlat(axis=1)\n",
    "        loss = JointLoss(ce, dc, 1, 1)\n",
    "        \n",
    "    if deep_supervision:\n",
    "        return DeepSupervisionLoss(loss)\n",
    "    \n",
    "    else:\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CrossEntropyLoss\n",
      "Testing DiceLoss\n",
      "Testing SoftCrossEntropyLoss\n",
      "Testing CrossEntropyDiceLoss\n",
      "Testing JaccardLoss\n",
      "Testing FocalLoss\n",
      "Testing LovaszLoss\n",
      "Testing TverskyLoss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/anaconda3/envs/fastai2/lib/python3.8/site-packages/kornia/augmentation/augmentation.py:1830: DeprecationWarning: GaussianBlur is no longer maintained and will be removed from the future versions. Please use RandomGaussianBlur instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Test if all losses are running\n",
    "n_classes = 2\n",
    "output = torch.randn(4, n_classes, 356, 356, requires_grad=True)\n",
    "target = torch.randint(0, n_classes, (4, 356, 356))\n",
    "for loss_name in LOSSES:\n",
    "    print(f'Testing {loss_name}')\n",
    "    tst = get_loss(loss_name, classes=list(range(1,n_classes))) \n",
    "    loss = tst(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/home/mag01ud/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CrossEntropyLoss\n",
      "Testing DiceLoss\n",
      "Testing SoftCrossEntropyLoss\n",
      "Testing CrossEntropyDiceLoss\n",
      "Testing JaccardLoss\n",
      "Testing FocalLoss\n",
      "Testing LovaszLoss\n",
      "Testing TverskyLoss\n"
     ]
    }
   ],
   "source": [
    "output_list = 2*[output]\n",
    "for loss_name in LOSSES:\n",
    "    print(f'Testing {loss_name}')\n",
    "    tst = get_loss(loss_name, deep_supervision=True, classes=list(range(1,n_classes))) \n",
    "    loss = tst(output_list, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/home/mag01ud/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Compare soft cross entropy loss with smooth_factor=0 to (fastai) cross entropy \n",
    "ce1 = get_loss('SoftCrossEntropyLoss', smooth_factor=0)\n",
    "ce2 = CrossEntropyLossFlat(axis=1)\n",
    "test_close(ce1(output, target), ce2(output, target), eps=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/home/mag01ud/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Compare soft cross entropy loss with smooth_factor=0 to cross entropy \n",
    "jc = get_loss('JaccardLoss')\n",
    "dc = get_loss('DiceLoss')\n",
    "dc_loss = dc(output, target)\n",
    "dc_to_jc = 2*dc_loss/(dc_loss+1) #it seems to be the other way around?\n",
    "test_close(jc(output, target), dc_to_jc, eps=1e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/home/mag01ud/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Compare TverskyLoss with alpha=0.5 and beta=0.5 to dice loss, should be equal\n",
    "tw = get_loss(\"TverskyLoss\", alpha=0.5, beta=0.5)\n",
    "test_close(dc(output, target), tw(output, target), eps=1e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/home/mag01ud/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Temporaty test if classes are working\n",
    "output = torch.randn(4, n_classes, 356, 356)\n",
    "output[:,1,...] = 0.5\n",
    "tst = get_loss(loss_name='DiceLoss', classes=None) \n",
    "tst2 = get_loss(loss_name='DiceLoss', classes=list(range(1,n_classes))) \n",
    "test_ne(tst(output, target), tst2(output, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/home/mag01ud/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
