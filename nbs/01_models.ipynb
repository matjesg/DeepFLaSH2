{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#architectures-\n",
    "ARCHITECTURES =  ['Unet', 'UnetPlusPlus', 'FPN', 'PAN', 'PSPNet', 'Linknet', 'DeepLabV3', 'DeepLabV3Plus'] #'MAnet',\n",
    "\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#encoders-\n",
    "ENCODERS = [*smp.encoders.encoders.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenation Models Pytorch Integration\n",
    "\n",
    "From the website: \n",
    "\n",
    "- High level API (just two lines to create a neural network)\n",
    "- 9 models architectures for binary and multi class segmentation (including legendary Unet)\n",
    "- 104 available encoders\n",
    "- All encoders have pre-trained weights for faster and better convergence\n",
    "\n",
    "See https://github.com/qubvel/segmentation_models.pytorch for API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_pretrained_options(encoder_name):\n",
    "    'Return available options for pretrained weights for a given encoder'\n",
    "    options = smp.encoders.encoders[encoder_name]['pretrained_settings'].keys()\n",
    "    return [*options, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_smp_model(arch, **kwargs):\n",
    "    'Create segmentation_models_pytorch model'\n",
    "    \n",
    "    assert arch in ARCHITECTURES, f'Select one of {ARCHITECTURES}'\n",
    "        \n",
    "    if arch==\"Unet\": model =  smp.Unet(**kwargs)\n",
    "    elif arch==\"UnetPlusPlus\": model = smp.UnetPlusPlus(**kwargs)\n",
    "    elif arch==\"MAnet\":model = smp.MAnet(**kwargs)\n",
    "    elif arch==\"FPN\": model = smp.FPN(**kwargs)\n",
    "    elif arch==\"PAN\": model = smp.PAN(**kwargs)\n",
    "    elif arch==\"PSPNet\": model = smp.PSPNet(**kwargs)\n",
    "    elif arch==\"Linknet\": model = smp.Linknet(**kwargs)\n",
    "    elif arch==\"DeepLabV3\": model = smp.DeepLabV3(**kwargs)\n",
    "    elif arch==\"DeepLabV3Plus\": model = smp.DeepLabV3Plus(**kwargs)\n",
    "    else: raise NotImplementedError\n",
    "    \n",
    "    setattr(model, 'kwargs', kwargs)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "bs = 2\n",
    "tile_shapes = [512] #1024\n",
    "in_channels = [1] #1,3,4\n",
    "classes = [2] # 2,5\n",
    "encoders = ENCODERS[1:2]#+ENCODERS[-1:]\n",
    "\n",
    "for ts in tile_shapes:\n",
    "    for in_c in in_channels:\n",
    "        for c in classes:\n",
    "            inp = torch.randn(bs, in_c, ts, ts)\n",
    "            out_shape = [bs, c, ts, ts]\n",
    "            for arch in ARCHITECTURES:\n",
    "                for encoder_name in encoders:\n",
    "                    model = create_smp_model(arch=arch, \n",
    "                                             encoder_name=encoder_name,\n",
    "                                             encoder_weights=None,\n",
    "                                             in_channels=in_c, \n",
    "                                             classes=c)\n",
    "                    out = model(inp)\n",
    "                    test_eq(out.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_smp_model(model, arch, file,  stats=None, pickle_protocol=2):\n",
    "    'Save smp model, optionally including  stats'\n",
    "    state = model.state_dict()\n",
    "    save_dict = {'model': state, 'arch': arch, 'stats': stats, **model.kwargs}\n",
    "    torch.save(save_dict, file, pickle_protocol=pickle_protocol, _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'Unet'\n",
    "file = 'tst.pth'\n",
    "stats = (1,1)\n",
    "kwargs = {'encoder_name': 'resnet34'}\n",
    "tst = create_smp_model(arch, **kwargs)\n",
    "save_smp_model(tst, arch, file, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_smp_model(file, device=None, strict=True, **kwargs):\n",
    "    'Loads smp model from file '\n",
    "    if isinstance(device, int): device = torch.device('cuda', device)\n",
    "    elif device is None: device = 'cpu'  \n",
    "    model_dict = torch.load(file, map_location=device)\n",
    "    state = model_dict.pop('model')    \n",
    "    stats = model_dict.pop('stats')    \n",
    "    model = create_smp_model(**model_dict)\n",
    "    model.load_state_dict(state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2, stats2 = load_smp_model(file)\n",
    "for p1, p2 in zip(tst.parameters(), tst2.parameters()):\n",
    "    test_eq(p1.detach(), p2.detach())\n",
    "test_eq(stats, stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
