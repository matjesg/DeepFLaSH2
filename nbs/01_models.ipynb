{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch, numpy as np\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "from fastcore.basics import patch\n",
    "from fastdownload import download_url\n",
    "from pathlib import Path\n",
    "import sys, subprocess\n",
    "from pip._internal.operations import freeze\n",
    "from transformers import SegformerForSemanticSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#architectures-\n",
    "ARCHITECTURES =  ['SegFormer', 'Unet', 'UnetPlusPlus', 'FPN', 'PAN', 'PSPNet', 'Linknet', 'DeepLabV3', 'DeepLabV3Plus'] #'MAnet',\n",
    "\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#encoders-\n",
    "ENCODERS = [*smp.encoders.encoders.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers/Huggingface Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SegFormer(torch.nn.Module):\n",
    "    def __init__(self, classes=2, in_channels=1, **kwargs):\n",
    "        super(SegFormer, self).__init__()\n",
    "        self.segformer = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\", \n",
    "                                                             ignore_mismatched_sizes=True,\n",
    "                                                             num_channels=in_channels,\n",
    "                                                             num_labels=classes,\n",
    "                                                             #id2label=id2label, label2id=label2id,\n",
    "                                                             reshape_last_stage=True)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        outputs = self.segformer(pixel_values=pixel_values)\n",
    "        return torch.nn.functional.interpolate(outputs.logits, scale_factor=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenation Models Pytorch Integration\n",
    "\n",
    "From the website: \n",
    "\n",
    "- High level API (just two lines to create a neural network)\n",
    "- 9 models architectures for binary and multi class segmentation (including legendary Unet)\n",
    "- 104 available encoders\n",
    "- All encoders have pre-trained weights for faster and better convergence\n",
    "\n",
    "See https://github.com/qubvel/segmentation_models.pytorch for API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_pretrained_options(encoder_name):\n",
    "    'Return available options for pretrained weights for a given encoder'\n",
    "    options = smp.encoders.encoders[encoder_name]['pretrained_settings'].keys()\n",
    "    return [*options, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_smp_model(arch, **kwargs):\n",
    "    'Create segmentation_models_pytorch model'\n",
    "    \n",
    "    assert arch in ARCHITECTURES, f'Select one of {ARCHITECTURES}'\n",
    "        \n",
    "    if arch==\"Unet\": model =  smp.Unet(**kwargs)\n",
    "    elif arch==\"UnetPlusPlus\": model = smp.UnetPlusPlus(**kwargs)\n",
    "    elif arch==\"MAnet\":model = smp.MAnet(**kwargs)\n",
    "    elif arch==\"FPN\": model = smp.FPN(**kwargs)\n",
    "    elif arch==\"PAN\": model = smp.PAN(**kwargs)\n",
    "    elif arch==\"PSPNet\": model = smp.PSPNet(**kwargs)\n",
    "    elif arch==\"Linknet\": model = smp.Linknet(**kwargs)\n",
    "    elif arch==\"DeepLabV3\": model = smp.DeepLabV3(**kwargs)\n",
    "    elif arch==\"DeepLabV3Plus\": model = smp.DeepLabV3Plus(**kwargs)\n",
    "    elif arch==\"SegFormer\": model = SegFormer(**kwargs)\n",
    "    else: raise NotImplementedError\n",
    "    \n",
    "    setattr(model, 'kwargs', kwargs)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.weight', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.classifier.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.batch_norm.running_mean', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized because the shapes did not match:\n",
      "- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "bs = 2\n",
    "tile_shapes = [512] #1024\n",
    "in_channels = [1] #1,3,4\n",
    "classes = [2] # 2,5\n",
    "encoders = ENCODERS[1:2]#+ENCODERS[-1:]\n",
    "\n",
    "for ts in tile_shapes:\n",
    "    for in_c in in_channels:\n",
    "        for c in classes:\n",
    "            inp = torch.randn(bs, in_c, ts, ts)\n",
    "            out_shape = [bs, c, ts, ts]\n",
    "            for arch in ARCHITECTURES:\n",
    "                for encoder_name in encoders:\n",
    "                    model = create_smp_model(arch=arch, \n",
    "                                             encoder_name=encoder_name,\n",
    "                                             encoder_weights=None,\n",
    "                                             in_channels=in_c, \n",
    "                                             classes=c)\n",
    "                    out = model(inp)\n",
    "                    test_eq(out.shape, out_shape)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_smp_model(model, arch, path, stats=None, pickle_protocol=2):\n",
    "    'Save smp model, optionally including  stats'\n",
    "    path = Path(path)\n",
    "    state = model.state_dict()\n",
    "    save_dict = {'model': state, 'arch': arch, 'stats': stats, **model.kwargs}\n",
    "    torch.save(save_dict, path, pickle_protocol=pickle_protocol, _use_new_zipfile_serialization=False)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'Unet'\n",
    "path = 'tst.pth'\n",
    "stats = (1,1)\n",
    "kwargs = {'encoder_name': 'resnet34'}\n",
    "tst = create_smp_model(arch, **kwargs)\n",
    "path = save_smp_model(tst, arch, path, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.weight', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.classifier.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.batch_norm.running_mean', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized because the shapes did not match:\n",
      "- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "arch = 'SegFormer'\n",
    "path = 'tst.pth'\n",
    "stats = (1,1)\n",
    "kwargs = {'encoder_name': 'resnet34'}\n",
    "tst = create_smp_model(arch, **kwargs)\n",
    "path = save_smp_model(tst, arch, path, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_smp_model(path, device=None, strict=True, **kwargs):\n",
    "    'Loads smp model from file '\n",
    "    path = Path(path)\n",
    "    if isinstance(device, int): device = torch.device('cuda', device)\n",
    "    elif device is None: device = 'cpu'  \n",
    "    model_dict = torch.load(path, map_location=device)\n",
    "    state = model_dict.pop('model')    \n",
    "    stats = model_dict.pop('stats')    \n",
    "    model = create_smp_model(**model_dict)\n",
    "    model.load_state_dict(state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.weight', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.classifier.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.batch_norm.running_mean', 'decode_head.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized because the shapes did not match:\n",
      "- segformer.encoder.patch_embeddings.0.proj.weight: found shape torch.Size([32, 3, 7, 7]) in the checkpoint and torch.Size([32, 1, 7, 7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tst2, stats2 = load_smp_model(path)\n",
    "for p1, p2 in zip(tst.parameters(), tst2.parameters()):\n",
    "    test_eq(p1.detach(), p2.detach())\n",
    "test_eq(stats, stats2)\n",
    "path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellpose integration\n",
    "\n",
    "for reliable cell and nucleus segmentation. Visit [cellpose](https://github.com/MouseLand/cellpose) for more information. \n",
    "\n",
    "Cellpose integration for deepflash2 is tested on version 0.6.6.dev13+g316927e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_cellpose_installation(show_progress=True):\n",
    "    tarball = 'cellpose-0.6.6.dev13+g316927e.tar.gz' # '316927eff7ad2201391957909a2114c68baee309'\n",
    "    try: \n",
    "        extract = [x for x in freeze.freeze() if x.startswith('cellpose')][0][-15:]\n",
    "        assert extract==tarball[-15:]\n",
    "    except:\n",
    "        print(f'Installing cellpose. Please wait.')\n",
    "        home_dir = Path.home()/'.deepflash2'\n",
    "        home_dir.mkdir(exist_ok=True, parents=True)\n",
    "        url = f'https://github.com/matjesg/deepflash2/releases/download/0.1.4/{tarball}'\n",
    "        file = download_url(url, home_dir, show_progress=show_progress)\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", '--no-deps', file.as_posix()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_diameters(masks):\n",
    "    'Get diameters from deepflash2 prediction'\n",
    "    from cellpose import utils\n",
    "    diameters = []\n",
    "    for m in masks:\n",
    "        _, comps = cv2.connectedComponents(m.astype('uint8'), connectivity=4)\n",
    "        diameters.append(utils.diameters(comps)[0])\n",
    "    return int(np.array(diameters).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_cellpose(probs, masks, model_type='nuclei', diameter=0, min_size=-1, gpu=True):\n",
    "    'Run cellpose on deepflash2 predictions'\n",
    "    check_cellpose_installation()\n",
    "\n",
    "    if diameter==0: \n",
    "        diameter = get_diameters(masks)\n",
    "    print(f'Using diameter of {diameter}')\n",
    "    \n",
    "    from cellpose import models, dynamics, utils\n",
    "    @patch\n",
    "    def _compute_masks(self:models.CellposeModel, dP, cellprob, p=None, niter=200,\n",
    "                        flow_threshold=0.4, interp=True, do_3D=False, min_size=15, resize=None, **kwargs):\n",
    "        \"\"\" compute masks using dynamics from dP and cellprob \"\"\"\n",
    "        if p is None:\n",
    "            p = dynamics.follow_flows(-1 * dP * mask / 5., niter=niter, interp=interp, use_gpu=self.gpu)\n",
    "        maski = dynamics.get_masks(p, iscell=mask, flows=dP, threshold=flow_threshold if not do_3D else None)\n",
    "        maski = utils.fill_holes_and_remove_small_masks(maski, min_size=min_size)\n",
    "        if resize is not None:\n",
    "            maski = transforms.resize_image(maski, resize[0], resize[1], \n",
    "                                            interpolation=cv2.INTER_NEAREST)\n",
    "        return maski, p\n",
    "    \n",
    "    model = models.Cellpose(gpu=gpu, model_type=model_type)\n",
    "    cp_masks = []\n",
    "    for prob, mask in zip(probs, masks):\n",
    "        cp_pred, _, _, _ = model.eval(prob, \n",
    "                                       net_avg=True,\n",
    "                                       augment=True,\n",
    "                                       diameter=diameter, \n",
    "                                       normalize=False,\n",
    "                                       min_size=min_size,\n",
    "                                       resample=True,\n",
    "                                       channels=[0,0])\n",
    "        cp_masks.append(cp_pred)\n",
    "    return cp_masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using diameter of 17.0\n",
      "2021-12-08 13:48:42,625 [INFO] WRITING LOG OUTPUT TO /media/data/home/mag01ud/.cellpose/run.log\n",
      "2021-12-08 13:48:43,818 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2021-12-08 13:48:43,818 [INFO] >>>> using GPU\n",
      "2021-12-08 13:48:43,861 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2021-12-08 13:48:46,569 [INFO] >>>> TOTAL TIME 2.71 sec\n"
     ]
    }
   ],
   "source": [
    "probs = [np.random.rand(512,512)]\n",
    "masks = [x>0. for x in probs]\n",
    "cp_preds = run_cellpose(probs, masks, diameter=17.)\n",
    "test_eq(probs[0].shape, cp_preds[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted tutorial.ipynb.\n",
      "Converted tutorial_gt.ipynb.\n",
      "Converted tutorial_pred.ipynb.\n",
      "Converted tutorial_train.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
