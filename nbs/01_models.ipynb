{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#architectures-\n",
    "ARCHITECTURES =  ['Unet', 'UnetPlusPlus', 'FPN', 'PAN', 'PSPNet', 'Linknet', 'DeepLabV3', 'DeepLabV3Plus'] #'MAnet',\n",
    "\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#encoders-\n",
    "ENCODERS = [*smp.encoders.encoders.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenation Models Pytorch Integration\n",
    "\n",
    "From the website: \n",
    "\n",
    "- High level API (just two lines to create a neural network)\n",
    "- 9 models architectures for binary and multi class segmentation (including legendary Unet)\n",
    "- 104 available encoders\n",
    "- All encoders have pre-trained weights for faster and better convergence\n",
    "\n",
    "See https://github.com/qubvel/segmentation_models.pytorch for API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_pretrained_options(encoder_name):\n",
    "    'Return available options for pretrained weights for a given encoder'\n",
    "    options = smp.encoders.encoders[encoder_name]['pretrained_settings'].keys()\n",
    "    return [*options, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_smp_model(arch, **kwargs):\n",
    "    'Create segmentation_models_pytorch model'\n",
    "    \n",
    "    assert arch in ARCHITECTURES, f'Select one of {ARCHITECTURES}'\n",
    "        \n",
    "    if arch==\"Unet\": model =  smp.Unet(**kwargs)\n",
    "    elif arch==\"UnetPlusPlus\": model = smp.UnetPlusPlus(**kwargs)\n",
    "    elif arch==\"MAnet\":model = smp.MAnet(**kwargs)\n",
    "    elif arch==\"FPN\": model = smp.FPN(**kwargs)\n",
    "    elif arch==\"PAN\": model = smp.PAN(**kwargs)\n",
    "    elif arch==\"PSPNet\": model = smp.PSPNet(**kwargs)\n",
    "    elif arch==\"Linknet\": model = smp.Linknet(**kwargs)\n",
    "    elif arch==\"DeepLabV3\": model = smp.DeepLabV3(**kwargs)\n",
    "    elif arch==\"DeepLabV3Plus\": model = smp.DeepLabV3Plus(**kwargs)\n",
    "    else: raise NotImplementedError\n",
    "    \n",
    "    setattr(model, 'kwargs', kwargs)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/anaconda3/envs/fastai2/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "bs = 2\n",
    "tile_shapes = [512] #1024\n",
    "in_channels = [1] #1,3,4\n",
    "classes = [2] # 2,5\n",
    "encoders = ENCODERS[1:2]#+ENCODERS[-1:]\n",
    "\n",
    "for ts in tile_shapes:\n",
    "    for in_c in in_channels:\n",
    "        for c in classes:\n",
    "            inp = torch.randn(bs, in_c, ts, ts)\n",
    "            out_shape = [bs, c, ts, ts]\n",
    "            for arch in ARCHITECTURES:\n",
    "                for encoder_name in encoders:\n",
    "                    model = create_smp_model(arch=arch, \n",
    "                                             encoder_name=encoder_name,\n",
    "                                             encoder_weights=None,\n",
    "                                             in_channels=in_c, \n",
    "                                             classes=c)\n",
    "                    out = model(inp)\n",
    "                    test_eq(out.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_smp_model(model, arch, file,  stats=None, pickle_protocol=2):\n",
    "    'Save smp model, optionally including  stats'\n",
    "    state = model.state_dict()\n",
    "    save_dict = {'model': state, 'arch': arch, 'stats': stats, **model.kwargs}\n",
    "    torch.save(save_dict, file, pickle_protocol=pickle_protocol, _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'Unet'\n",
    "file = 'tst.pth'\n",
    "stats = (1,1)\n",
    "kwargs = {'encoder_name': 'resnet34'}\n",
    "tst = create_smp_model(arch, **kwargs)\n",
    "save_smp_model(tst, arch, file, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_smp_model(file, device=None, strict=True, **kwargs):\n",
    "    'Loads smp model from file '\n",
    "    if isinstance(device, int): device = torch.device('cuda', device)\n",
    "    elif device is None: device = 'cpu'  \n",
    "    model_dict = torch.load(file, map_location=device)\n",
    "    state = model_dict.pop('model')    \n",
    "    stats = model_dict.pop('stats')    \n",
    "    model = create_smp_model(**model_dict)\n",
    "    model.load_state_dict(state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2, stats2 = load_smp_model(file)\n",
    "for p1, p2 in zip(tst.parameters(), tst2.parameters()):\n",
    "    test_eq(p1.detach(), p2.detach())\n",
    "test_eq(stats, stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Supervision: Unet Patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn\n",
    "from fastcore.basics import patch\n",
    "from segmentation_models_pytorch.unet.decoder import UnetDecoder\n",
    "from segmentation_models_pytorch.encoders import get_encoder\n",
    "from segmentation_models_pytorch.base import SegmentationModel\n",
    "from segmentation_models_pytorch.base import SegmentationHead, ClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiSegmentationHead(nn.Module):\n",
    "    def __init__(self, heads):\n",
    "        super().__init__()\n",
    "        self.heads = [SegmentationHead(**head) for head in heads]\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        for head in self.heads: head.to(xs[0])\n",
    "        return [head(x) for head, x in zip(self.heads, xs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def forward(self:smp.unet.decoder.UnetDecoder, *features):\n",
    "\n",
    "    seg_outputs = []\n",
    "    features = features[1:]    # remove first skip with same spatial resolution\n",
    "    features = features[::-1]  # reverse channels to start from head of encoder\n",
    "\n",
    "    head = features[0]\n",
    "    skips = features[1:]\n",
    "\n",
    "    x = self.center(head)\n",
    "    for i, decoder_block in enumerate(self.blocks):\n",
    "        skip = skips[i] if i < len(skips) else None\n",
    "        x = decoder_block(x, skip)\n",
    "        seg_outputs.append(x)\n",
    "\n",
    "    #if self.deep_supervision:\n",
    "    return seg_outputs[::-1]\n",
    "    \n",
    "    \n",
    "    #else:\n",
    "    #    return seg_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Optional, Union, List\n",
    "@patch\n",
    "def __init__(\n",
    "    self:smp.unet.model.Unet,\n",
    "    encoder_name: str = \"resnet34\",\n",
    "    encoder_depth: int = 5,\n",
    "    encoder_weights: Optional[str] = \"imagenet\",\n",
    "    decoder_use_batchnorm: bool = True,\n",
    "    decoder_channels: List[int] = (256, 128, 64, 32, 16),\n",
    "    decoder_attention_type: Optional[str] = None,\n",
    "    in_channels: int = 3,\n",
    "    classes: int = 1,\n",
    "    activation: Optional[Union[str, callable]] = None,\n",
    "    aux_params: Optional[dict] = None,\n",
    "    deep_supervision:bool = True,\n",
    "):\n",
    "    super(smp.unet.model.Unet, self).__init__()\n",
    "\n",
    "    self.encoder = get_encoder(\n",
    "        encoder_name,\n",
    "        in_channels=in_channels,\n",
    "        depth=encoder_depth,\n",
    "        weights=encoder_weights,\n",
    "    )\n",
    "\n",
    "    self.decoder = UnetDecoder(\n",
    "        encoder_channels=self.encoder.out_channels,\n",
    "        decoder_channels=decoder_channels,\n",
    "        n_blocks=encoder_depth,\n",
    "        use_batchnorm=decoder_use_batchnorm,\n",
    "        center=True if encoder_name.startswith(\"vgg\") else False,\n",
    "        attention_type=decoder_attention_type,\n",
    "    )\n",
    "\n",
    "    if deep_supervision:\n",
    "        self.segmentation_head = MultiSegmentationHead(\n",
    "            [{\n",
    "            \"in_channels\":in_channels,\n",
    "            \"out_channels\":classes,\n",
    "            \"activation\":activation,\n",
    "            \"kernel_size\":3\n",
    "            } for head, in_channels in enumerate(decoder_channels[::-1])]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        self.segmentation_head = SegmentationHead(\n",
    "            in_channels=decoder_channels[-1],\n",
    "            out_channels=classes,\n",
    "            activation=activation,\n",
    "            kernel_size=3,\n",
    "        )\n",
    "    \n",
    "\n",
    "    if aux_params is not None:\n",
    "        self.classification_head = ClassificationHead(\n",
    "            in_channels=self.encoder.out_channels[-1], **aux_params\n",
    "        )\n",
    "    else:\n",
    "        self.classification_head = None\n",
    "\n",
    "    self.name = \"u-{}\".format(encoder_name)\n",
    "    self.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = create_smp_model(arch='Unet', \n",
    "                                             encoder_name=encoder_name,\n",
    "                                             encoder_weights=None,\n",
    "                                             in_channels=in_c, \n",
    "                                             classes=c)\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
